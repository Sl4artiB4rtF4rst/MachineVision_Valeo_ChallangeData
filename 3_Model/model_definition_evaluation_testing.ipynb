{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition and Evaluation\n",
    "## Table of Contents\n",
    "1. [Model Selection](#model-selection)\n",
    "2. [Feature Engineering](#feature-engineering)\n",
    "3. [Hyperparameter Tuning](#hyperparameter-tuning)\n",
    "4. [Implementation](#implementation)\n",
    "5. [Evaluation Metrics](#evaluation-metrics)\n",
    "6. [Comparative Analysis](#comparative-analysis)\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:49.440498Z",
     "start_time": "2026-01-20T14:47:49.280165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#reset all variables when running again to avoid any mistakes\n",
    "\n",
    "%reset -f"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:52.664270Z",
     "start_time": "2026-01-20T14:47:49.448500Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "import gc\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from matplotlib.ticker import StrMethodFormatter\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "We are considering and evaluating self-defined CNN and pretrained CNNs. Convolutional Neural Networks are proven to work well for the task of image classification. Most likely transformer models could potentially have an even better performance but it is highly likely that the added complexity will not justify the potential increase in performance.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:52.677662Z",
     "start_time": "2026-01-20T14:47:52.671274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# choose main hyperparameters here\n",
    "\n",
    "#data / feature selections\n",
    "balanced_flag = False\n",
    "\n",
    "#Traing data splits :\n",
    "test_split = 0.2\n",
    "val_split = 0.20 # remember - this is fractional  after the test data has been split from the initial balanced sub dataset\n",
    "\n",
    "# image parameters\n",
    "target_size = (299,299) #pixel size to load img\n",
    "\n",
    "#select data augmentation\n",
    "aug_flag = True\n",
    "#augmentation params\n",
    "horizontal_flip=False\n",
    "vertical_flip=False\n",
    "rotation_range=15\n",
    "shear_range= 1\n",
    "zoom_range = 0.07\n",
    "\n",
    "#training\n",
    "max_epochs = 100\n",
    "loss_stop_patience = 7\n",
    "learningRate = 0.001\n",
    "\n",
    "loss_stop_patience_multi = [5,6,12] #patience in each step\n",
    "\n",
    "#class weights\n",
    "Use_class_weights = True\n",
    "\n",
    "#early stopping\n",
    "StoppingSelector = 'val_loss' #valid values: 'val_loss','val_f1'\n",
    "\n",
    "#flags for models to include\n",
    "model1_flag = False\n",
    "model2_flag = False\n",
    "model3_flag = False\n",
    "feature_extract_flag = False\n",
    "fine_tune_flag = False\n",
    "full_fine_tune_flag = False\n",
    "multi_phase_fine_tune_flag = False\n",
    "\n",
    "reducedClassNumber_flag = False\n",
    "\n",
    "EfficientNet_Flag = True\n",
    "\n",
    "#set batch size according to balanc selection\n",
    "if balanced_flag:\n",
    "    batch_size = 8 #later player around with batch size to see how it affects performance\n",
    "else:\n",
    "    batch_size = 32 #hopefully speeds up training"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:52.686048Z",
     "start_time": "2026-01-20T14:47:52.682668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# specify the model loss function\n",
    "\n",
    "#options: 'normal' :   tf.keras.losses.CategoricalCrossentropy()    , 'focal' : tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "lossSelect = 'normal'\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:52.729700Z",
     "start_time": "2026-01-20T14:47:52.698054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#select optimizer\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learningRate)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:52.740183Z",
     "start_time": "2026-01-20T14:47:52.736703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#make customizable string to add to dir for testing\n",
    "\n",
    "custom_save_str = '_focalLoss'"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "[Describe any additional feature engineering you've performed beyond what was done for the baseline model.]\n",
    "\n",
    "We test data augmentation (to varying degrees), dataset balancing and class weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:52.774134Z",
     "start_time": "2026-01-20T14:47:52.748180Z"
    }
   },
   "source": [
    "# Path Definitions to relevant data + data loading\n",
    "\n",
    "base_file_path = 'C:/Users/nikoLocal/Documents/Opencampus/Machine_Vision_challenge_data/'\n",
    "image_path = base_file_path + '/input_train/input_train'\n",
    "\n",
    "label_csv_name = 'Y_train_eVW9jym.csv'\n",
    "\n",
    "#Loading .csv data to dataframes\n",
    "train_df = pd.read_csv(os.path.join(base_file_path, label_csv_name))\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:52.805602Z",
     "start_time": "2026-01-20T14:47:52.786141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#DataFrame Preprocessing\n",
    "\n",
    "\n",
    "#add another column to the dataframe according to dictionaries to map Labels correctly to numbers\n",
    "dict_numbers = {'GOOD': 0,'Boucle plate':1,'Lift-off blanc':2,'Lift-off noir':3,'Missing':4,'Short circuit MOS':5}\n",
    "dict_strings = {'GOOD': '0_GOOD','Boucle plate':'1_Flat loop','Lift-off blanc':'2_White lift-off','Lift-off noir':'3_Black lift-off','Missing':'4_Missing','Short circuit MOS':'5_Short circuit MOS'}\n",
    "# for Test Data (\"random submission\" dataframe)\n",
    "dict_strings_sub = {0: '0_GOOD',1:'1_Flat loop',2:'2_White lift-off',3:'3_Black lift-off',4:'4_Missing',5:'5_Short circuit MOS',6:'6_Drift'}\n",
    "\n",
    "#list of all labels in the data\n",
    "label_list = ['0_GOOD','1_Flat loop','2_White lift-off','3_Black lift-off','4_Missing','5_Short circuit MOS']\n",
    "\n",
    "#create new columns in DFs via .map() method\n",
    "train_df['LabelNum'] = train_df['Label'].map(dict_numbers)\n",
    "train_df['LabelStr'] = train_df['Label'].map(dict_strings)\n",
    "\n",
    "#number of classes\n",
    "num_classes = len(label_list)\n",
    "\n",
    "# get counts of label with the least entries\n",
    "countList = train_df['LabelStr'].value_counts()\n",
    "minCounts = countList.min()\n",
    "\n",
    "BalancedDF = pd.DataFrame()\n",
    "#concat sampled dataframes for each included label\n",
    "for i in range(num_classes):\n",
    "    BalancedDF = pd.concat([BalancedDF,train_df[train_df['LabelStr'] == label_list[i]].sample(n=minCounts)],axis=0)\n",
    "\n",
    "#split dataframe according to fractional test size\n",
    "train_df_balanced, test_df_balanced = train_test_split(BalancedDF, test_size=test_split, random_state=42) #keep random state constant to ensure\n",
    "\n",
    "train_df_train, train_df_test = train_test_split(train_df, test_size=test_split, random_state=42) #keep random state constant to ensure"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:52.826827Z",
     "start_time": "2026-01-20T14:47:52.822611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#test if worked as intended\n",
    "print('Balanced DF Label Counts:')\n",
    "print(BalancedDF['LabelStr'].value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced DF Label Counts:\n",
      "LabelStr\n",
      "0_GOOD                 71\n",
      "1_Flat loop            71\n",
      "2_White lift-off       71\n",
      "3_Black lift-off       71\n",
      "4_Missing              71\n",
      "5_Short circuit MOS    71\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:52.897190Z",
     "start_time": "2026-01-20T14:47:52.891856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#test if worked as intended\n",
    "print('DF Label Counts:')\n",
    "print(train_df['LabelStr'].value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Label Counts:\n",
      "LabelStr\n",
      "4_Missing              6472\n",
      "0_GOOD                 1235\n",
      "2_White lift-off        270\n",
      "5_Short circuit MOS     126\n",
      "3_Black lift-off        104\n",
      "1_Flat loop              71\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:52.969284Z",
     "start_time": "2026-01-20T14:47:52.962220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#compute class weights for use of unbalanced datasets\n",
    "\n",
    "class_numbers = np.unique(train_df_train['LabelNum'])\n",
    "\n",
    "class_weights_unb = compute_class_weight(class_weight='balanced' ,classes = class_numbers,y=train_df_train['LabelNum'])\n",
    "class_weights_b = compute_class_weight(class_weight='balanced' ,classes = class_numbers,y=train_df_balanced['LabelNum'])\n",
    "equal_weights = np.ones(num_classes)\n",
    "\n",
    "#make dicts that can be used by keras\n",
    "class_w_unb_dict = dict(zip(class_numbers, class_weights_unb))\n",
    "class_w_b_dict = dict(zip(class_numbers, class_weights_b))\n",
    "class_w_equal_dict = dict(zip(class_numbers, equal_weights))"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:52.993883Z",
     "start_time": "2026-01-20T14:47:52.979289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make a dataset with only labels: 0_Good, 1_Flat loop and 2_Defective\n",
    "# in order to test whether flat loop can be recognized with high precision by a NN\n",
    "\n",
    "#make a deepcopy of existing df\n",
    "df_reduced_labels = train_df.copy(deep = True)\n",
    "\n",
    "#dict_strings = {'GOOD': '0_GOOD','Boucle plate':'1_Flat loop','Lift-off blanc':'2_White lift-off','Lift-off noir':'3_Black lift-off','Missing':'4_Missing','Short circuit MOS':'5_Short circuit MOS'}\n",
    "\n",
    "df_reduced_labels.loc[df_reduced_labels['LabelStr'] == '2_White lift-off', 'LabelStr'] = '2_Defective'\n",
    "df_reduced_labels.loc[df_reduced_labels['LabelStr'] == '3_Black lift-off', 'LabelStr'] = '2_Defective'\n",
    "df_reduced_labels.loc[df_reduced_labels['LabelStr'] == '4_Missing', 'LabelStr'] = '2_Defective'\n",
    "df_reduced_labels.loc[df_reduced_labels['LabelStr'] == '5_Short circuit MOS', 'LabelStr'] = '2_Defective'\n",
    "\n",
    "df_reduced_labels.loc[df_reduced_labels['LabelNum'] == 2, 'LabelNum'] = 2\n",
    "df_reduced_labels.loc[df_reduced_labels['LabelNum'] == 3, 'LabelNum'] = 2\n",
    "df_reduced_labels.loc[df_reduced_labels['LabelNum'] == 4, 'LabelNum'] = 2\n",
    "df_reduced_labels.loc[df_reduced_labels['LabelNum'] == 5, 'LabelNum'] = 2\n",
    "\n",
    "# split into training and test data\n",
    "df_reduced_labels_train, df_reduced_labels_test = train_test_split(df_reduced_labels, test_size=test_split, random_state=42) #keep random state constant to ensure\n",
    "\n",
    "#class weights for this dataset\n",
    "class_numbers_redLabel = np.unique(df_reduced_labels_train['LabelNum'])\n",
    "\n",
    "class_weights_redLabel = compute_class_weight(class_weight='balanced' ,classes = class_numbers_redLabel,y=df_reduced_labels_train['LabelNum'])\n",
    "\n",
    "#make dicts that can be used by keras\n",
    "class_weights_redLabel_dict = dict(zip(class_numbers_redLabel, class_weights_redLabel))\n",
    "\n",
    "num_classes_redLabel = 3\n",
    "\n",
    "label_list_reduced = ['0_Good','1_Flat Loop','2_Defective']"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:53.012289Z",
     "start_time": "2026-01-20T14:47:53.003888Z"
    }
   },
   "cell_type": "code",
   "source": "df_reduced_labels['LabelStr'].value_counts()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelStr\n",
       "2_Defective    6972\n",
       "0_GOOD         1235\n",
       "1_Flat loop      71\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "[Discuss any hyperparameter tuning methods you've applied, such as Grid Search or Random Search, and the rationale behind them.]\n",
    "So far we have done hyperparameters variation \"by hand\" only. Some parameters, such as the image size and data augmentation have been systemarically varied and the effects on model performance noted.\n",
    "\n",
    "We plan to do more hyperparamter tuning in the future."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:53.094216Z",
     "start_time": "2026-01-20T14:47:53.089332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make a unique string (name) to save model and evaluation to file\n",
    "# incorporate most important hyperparameters\n",
    "# make a subfolder for one set of hyperparameters for more tidy folder and file structure\n",
    "\n",
    "if aug_flag:\n",
    "    augmentation_str = 'Aug'\n",
    "else:\n",
    "    augmentation_str = 'NoAug'\n",
    "\n",
    "if balanced_flag:\n",
    "    balance_str = 'balanced'\n",
    "else:\n",
    "    balance_str = 'unbalanced'\n",
    "\n",
    "#class weights\n",
    "if Use_class_weights:\n",
    "    Cweights_str = '_Cweights'\n",
    "else:\n",
    "    Cweights_str = ''\n",
    "\n",
    "hyperparam_name = 'ImgSz_{}_{}_{}{}{}'.format(target_size[0],augmentation_str,balance_str,Cweights_str,custom_save_str)\n",
    "hyperparam_dir = os.path.join(base_file_path,'model_evaluation')\n",
    "hyperparam_dir = os.path.join(hyperparam_dir,hyperparam_name)\n",
    "#check if folder exists - if not create it\n",
    "if not os.path.isdir(hyperparam_dir):\n",
    "    os.makedirs(hyperparam_dir)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:55.134665Z",
     "start_time": "2026-01-20T14:47:53.117228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# initialize ImageDataGenerators\n",
    "# use ImageDataGen because it has method flow_from_dataframe() that works really well together with pandas dataframes\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# although deprecated the functionality can be used as discussed in feedback session\n",
    "\n",
    "# HYPERPARAMTERS ########\n",
    "\n",
    "\n",
    "class_mode = 'categorical' # how to store labels - either categorical (one-hot encoding) or as numbers\n",
    "#class_mode = 'input'\n",
    "labelCol = 'LabelStr'\n",
    "#########################\n",
    "\n",
    "#normalize pixel intensities\n",
    "rescale = 1.0/255.0\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rotation_range=0.0,\n",
    "    shear_range=0.0,\n",
    "    rescale=rescale,\n",
    "    validation_split=val_split)\n",
    "\n",
    "datagen_augmentation = ImageDataGenerator(\n",
    "    horizontal_flip=horizontal_flip,\n",
    "    vertical_flip=vertical_flip,\n",
    "    rotation_range=rotation_range,\n",
    "    shear_range= shear_range,\n",
    "    zoom_range = zoom_range,\n",
    "    rescale=rescale,\n",
    "    validation_split=val_split)\n",
    "\n",
    "datagen_test = ImageDataGenerator(\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rotation_range=0.0,\n",
    "    shear_range=0.0,\n",
    "    rescale=rescale,\n",
    "    validation_split=0.0)\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "#unbalanced datasets\n",
    "\n",
    "train_generator_unbalanced = datagen.flow_from_dataframe(\n",
    "    train_df_train,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "train_generator_unbalanced_val = datagen.flow_from_dataframe(\n",
    "    train_df_train,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation')\n",
    "\n",
    "train_generator_unbalanced_aug = datagen_augmentation.flow_from_dataframe(\n",
    "    train_df_train,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "train_generator_unbalanced_val_aug = datagen_augmentation.flow_from_dataframe(\n",
    "    train_df_train,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation')\n",
    "\n",
    "test_generator_unbalanced = datagen_test.flow_from_dataframe(\n",
    "    train_df_test,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "test_generator_unbalanced_metrics = datagen_test.flow_from_dataframe(\n",
    "    train_df_test,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=1,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    train_df_balanced,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "train_generator_val = datagen.flow_from_dataframe(\n",
    "    train_df_balanced,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation')\n",
    "\n",
    "train_generator_aug = datagen_augmentation.flow_from_dataframe(\n",
    "    train_df_balanced,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "train_generator_aug_val = datagen_augmentation.flow_from_dataframe(\n",
    "    train_df_balanced,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation')\n",
    "\n",
    "test_generator = datagen_test.flow_from_dataframe(\n",
    "    test_df_balanced,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "test_generator_metrics = datagen_test.flow_from_dataframe(\n",
    "    test_df_balanced,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=1,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "# generators for transfer learning - color mode is color here. Pretrained models expect color input\n",
    "\n",
    "train_generator_unbalanced_color = datagen.flow_from_dataframe(\n",
    "    train_df_train,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "train_generator_unbalanced_val_color = datagen.flow_from_dataframe(\n",
    "    train_df_train,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation')\n",
    "\n",
    "test_generator_unbalanced_color = datagen_test.flow_from_dataframe(\n",
    "    train_df_test,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "train_generator_unbalanced_aug_color = datagen_augmentation.flow_from_dataframe(\n",
    "    train_df_train,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "test_generator_unbalanced_metrics_color = datagen_test.flow_from_dataframe(\n",
    "    train_df_test,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=1,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "train_generator_color = datagen.flow_from_dataframe(\n",
    "    train_df_balanced,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "train_generator_val_color = datagen.flow_from_dataframe(\n",
    "    train_df_balanced,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation')\n",
    "\n",
    "train_generator_aug_color = datagen_augmentation.flow_from_dataframe(\n",
    "    train_df_balanced,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "train_generator_aug_val_color = datagen_augmentation.flow_from_dataframe(\n",
    "    train_df_balanced,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation')\n",
    "\n",
    "test_generator_color = datagen_test.flow_from_dataframe(\n",
    "    test_df_balanced,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "test_generator_metrics_color = datagen_test.flow_from_dataframe(\n",
    "    test_df_balanced,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=1,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='training')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5298 validated image filenames belonging to 6 classes.\n",
      "Found 1324 validated image filenames belonging to 6 classes.\n",
      "Found 5298 validated image filenames belonging to 6 classes.\n",
      "Found 1324 validated image filenames belonging to 6 classes.\n",
      "Found 1656 validated image filenames belonging to 6 classes.\n",
      "Found 1656 validated image filenames belonging to 6 classes.\n",
      "Found 272 validated image filenames belonging to 6 classes.\n",
      "Found 68 validated image filenames belonging to 6 classes.\n",
      "Found 272 validated image filenames belonging to 6 classes.\n",
      "Found 68 validated image filenames belonging to 6 classes.\n",
      "Found 86 validated image filenames belonging to 6 classes.\n",
      "Found 86 validated image filenames belonging to 6 classes.\n",
      "Found 5298 validated image filenames belonging to 6 classes.\n",
      "Found 1324 validated image filenames belonging to 6 classes.\n",
      "Found 1656 validated image filenames belonging to 6 classes.\n",
      "Found 5298 validated image filenames belonging to 6 classes.\n",
      "Found 1656 validated image filenames belonging to 6 classes.\n",
      "Found 272 validated image filenames belonging to 6 classes.\n",
      "Found 68 validated image filenames belonging to 6 classes.\n",
      "Found 272 validated image filenames belonging to 6 classes.\n",
      "Found 68 validated image filenames belonging to 6 classes.\n",
      "Found 86 validated image filenames belonging to 6 classes.\n",
      "Found 86 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2026-01-20T14:47:55.144671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#dataset for reduced class number\n",
    "\n",
    "train_generator_redLabel = datagen.flow_from_dataframe(\n",
    "    df_reduced_labels_train,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "train_generator_redLabel_val = datagen.flow_from_dataframe(\n",
    "    df_reduced_labels_train,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation')\n",
    "\n",
    "test_generator_redLabel = datagen_test.flow_from_dataframe(\n",
    "    df_reduced_labels_test,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "train_generator_redLabel_aug = datagen_augmentation.flow_from_dataframe(\n",
    "    df_reduced_labels_train,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "test_generator_redLabel_metrics = datagen_test.flow_from_dataframe(\n",
    "    df_reduced_labels_test,\n",
    "    image_path,\n",
    "    x_col='filename',\n",
    "    y_col=labelCol,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=1,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='training')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5298 validated image filenames belonging to 3 classes.\n",
      "Found 1324 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "[Implement the final model(s) you've selected based on the above steps.]\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:04.537410Z",
     "start_time": "2026-01-19T11:22:04.051299Z"
    }
   },
   "source": [
    "# build a model to be used as baseline model\n",
    "# use \"simplest\" CNN as baseline\n",
    "\n",
    "model_1_CNN = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input((target_size[0], target_size[1], 1)),  #image are greyscale - so in total dim (width,height,1)\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model_2_CNN = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input((target_size[0], target_size[1], 1)),  #image are greyscale - so in total dim (width,height,1)\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model_3_CNN = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input((target_size[0], target_size[1], 1)),  #image are greyscale - so in total dim (width,height,1)\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model_1_CNN.summary()\n",
    "model_2_CNN.summary()\n",
    "model_3_CNN.summary()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m297\u001B[0m, \u001B[38;5;34m297\u001B[0m, \u001B[38;5;34m64\u001B[0m)   │           \u001B[38;5;34m640\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001B[38;5;33mMaxPooling2D\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m148\u001B[0m, \u001B[38;5;34m148\u001B[0m, \u001B[38;5;34m64\u001B[0m)   │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1401856\u001B[0m)        │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │    \u001B[38;5;34m89,718,848\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)              │           \u001B[38;5;34m390\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">297</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">297</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1401856</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">89,718,848</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m89,719,878\u001B[0m (342.25 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,719,878</span> (342.25 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m89,719,878\u001B[0m (342.25 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,719,878</span> (342.25 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m297\u001B[0m, \u001B[38;5;34m297\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │           \u001B[38;5;34m320\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m148\u001B[0m, \u001B[38;5;34m148\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m146\u001B[0m, \u001B[38;5;34m146\u001B[0m, \u001B[38;5;34m64\u001B[0m)   │        \u001B[38;5;34m18,496\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m73\u001B[0m, \u001B[38;5;34m73\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001B[38;5;33mFlatten\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m341056\u001B[0m)         │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │    \u001B[38;5;34m43,655,296\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)              │           \u001B[38;5;34m774\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">297</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">297</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">146</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">146</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341056</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">43,655,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m43,674,886\u001B[0m (166.61 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,674,886</span> (166.61 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m43,674,886\u001B[0m (166.61 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,674,886</span> (166.61 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_2\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m297\u001B[0m, \u001B[38;5;34m297\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │           \u001B[38;5;34m320\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m148\u001B[0m, \u001B[38;5;34m148\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m146\u001B[0m, \u001B[38;5;34m146\u001B[0m, \u001B[38;5;34m64\u001B[0m)   │        \u001B[38;5;34m18,496\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m73\u001B[0m, \u001B[38;5;34m73\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m71\u001B[0m, \u001B[38;5;34m71\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │        \u001B[38;5;34m73,856\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m35\u001B[0m, \u001B[38;5;34m35\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001B[38;5;33mFlatten\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m156800\u001B[0m)         │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │    \u001B[38;5;34m20,070,528\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m8,256\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)              │           \u001B[38;5;34m390\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">297</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">297</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">146</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">146</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156800</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,070,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m20,171,846\u001B[0m (76.95 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,171,846</span> (76.95 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m20,171,846\u001B[0m (76.95 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,171,846</span> (76.95 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 484
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:04.702534Z",
     "start_time": "2026-01-19T11:22:04.695015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#loss\n",
    "\n",
    "if balanced_flag:\n",
    "    focal_alpha = class_weights_b\n",
    "else:\n",
    "    focal_alpha = class_weights_unb\n",
    "\n",
    "# callback that monitors validation accuracy / loss\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "\n",
    "\n",
    "match StoppingSelector:\n",
    "    case 'val_loss':\n",
    "        StopCallback = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            min_delta=0.01,\n",
    "            patience= loss_stop_patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose = 2,\n",
    "            start_from_epoch = 1\n",
    "        )\n",
    "    case 'val_f1':\n",
    "        StopCallback = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_f1_score',\n",
    "            min_delta=0.005,\n",
    "            patience= loss_stop_patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose = 2,\n",
    "            mode='max'\n",
    "        )\n",
    "\n",
    "class ResetValLossOnTrainBegin(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        #set val loss to a high value in case there is a history left\n",
    "        logs[\"val_loss\"] =  1e3\n"
   ],
   "outputs": [],
   "execution_count": 485
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:04.713845Z",
     "start_time": "2026-01-19T11:22:04.709539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load weights gained by training from medical MRI data into inception V3\n",
    "\n",
    "# Load pre-trained InceptionV3 with correct input size\n",
    "\n",
    "#path to weights\n",
    "weights_subpath = 'pre_trained_models/radiology_net/InceptionV3.pth'\n",
    "medical_weights_path = os.path.join(base_file_path,weights_subpath)\n",
    "\n",
    "#convert weights to keras format\n",
    "\n",
    "#base_transfer_model_medical = tf.keras.applications.InceptionV3(\n",
    "#    weights=medical_weights_path,\n",
    "#    include_top=False,\n",
    "#    input_shape=(target_size[0], target_size[0], 3)\n",
    "#)\n"
   ],
   "outputs": [],
   "execution_count": 486
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:04.727014Z",
     "start_time": "2026-01-19T11:22:04.723850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#use the custom library from the weights provider\n",
    "#https://github.com/AIlab-RITEH/RadiologyNET-TL-models\n",
    "\n",
    "#import models\n",
    "#import torch\n",
    "\n",
    "#model_med_torch = models.InceptionV3(pretrained=False, number_of_classes=6)\n",
    "#models.transfer_weights_to_model(path=medical_weights_path, target_model=model_med_torch, device='cpu')\n",
    "\n",
    "#test\n",
    "#onnx_program = torch.onnx.export(model_med_torch, dynamo=True)"
   ],
   "outputs": [],
   "execution_count": 487
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:06.164710Z",
     "start_time": "2026-01-19T11:22:04.736627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Transfer learning model - feature extraction\n",
    "\n",
    "# Load pre-trained InceptionV3 with correct input size\n",
    "base_transfer_model = tf.keras.applications.InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(target_size[0], target_size[0], 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers for feature extraction\n",
    "base_transfer_model.trainable = False\n",
    "\n",
    "# Simple classification head\n",
    "# - GlobalAveragePooling2D reduces spatial dimensions\n",
    "# - Final Dense layer maps to class probabilities\n",
    "inception_feature_extraction_model = tf.keras.Sequential([\n",
    "    base_transfer_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "#select based on Str\n",
    "if lossSelect == 'normal':\n",
    "    loss_fun_feat = tf.keras.losses.CategoricalCrossentropy()\n",
    "else:\n",
    "    loss_fun_feat = tf.keras.losses.CategoricalFocalCrossentropy(alpha = focal_alpha,gamma = 2)\n",
    "\n",
    "inception_feature_extraction_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learningRate),\n",
    "    loss=loss_fun_feat,\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "    #metrics=[\"accuracy\",'precision',]\n",
    "    weighted_metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    ")\n",
    "\n",
    "inception_feature_extraction_model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_3\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (\u001B[38;5;33mFunctional\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m2048\u001B[0m)     │    \u001B[38;5;34m21,802,784\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)              │        \u001B[38;5;34m12,294\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,294</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m21,815,078\u001B[0m (83.22 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,815,078</span> (83.22 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m12,294\u001B[0m (48.02 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,294</span> (48.02 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m21,802,784\u001B[0m (83.17 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> (83.17 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 488
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:07.591019Z",
     "start_time": "2026-01-19T11:22:06.175711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# inception model with last 20 layers unfrozen\n",
    "\n",
    "# Load pre-trained InceptionV3 with correct input size\n",
    "base_transfer_model_2 = tf.keras.applications.InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(target_size[0], target_size[0], 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers except last few blocks\n",
    "base_transfer_model_2.trainable = True\n",
    "for layer in base_transfer_model_2.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Simple classification head\n",
    "# - GlobalAveragePooling2D reduces spatial dimensions\n",
    "# - Final Dense layer maps to class probabilities\n",
    "inception_fine_tune_model = tf.keras.Sequential([\n",
    "    base_transfer_model_2,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "#select based on Str\n",
    "if lossSelect == 'normal':\n",
    "    loss_fun_fine = tf.keras.losses.CategoricalCrossentropy()\n",
    "else:\n",
    "    loss_fun_fine = tf.keras.losses.CategoricalFocalCrossentropy(alpha = focal_alpha,gamma = 2)\n",
    "\n",
    "inception_fine_tune_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=loss_fun_fine,\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "    #metrics=[\"accuracy\",'precision',]\n",
    "    weighted_metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    ")\n",
    "\n",
    "inception_fine_tune_model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_4\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (\u001B[38;5;33mFunctional\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m2048\u001B[0m)     │    \u001B[38;5;34m21,802,784\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)              │        \u001B[38;5;34m12,294\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,294</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m21,815,078\u001B[0m (83.22 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,815,078</span> (83.22 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,947,654\u001B[0m (7.43 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,947,654</span> (7.43 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m19,867,424\u001B[0m (75.79 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,867,424</span> (75.79 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 489
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:08.991477Z",
     "start_time": "2026-01-19T11:22:07.616027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# inception model with all layers unfrozen\n",
    "\n",
    "# Load pre-trained InceptionV3 with correct input size\n",
    "base_transfer_model_3 = tf.keras.applications.InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(target_size[0], target_size[0], 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers except last few blocks\n",
    "base_transfer_model_3.trainable = True\n",
    "#for layer in base_transfer_model_3.layers[:-20]:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# Simple classification head\n",
    "# - GlobalAveragePooling2D reduces spatial dimensions\n",
    "# - Final Dense layer maps to class probabilities\n",
    "inception_full_fine_tune_model = tf.keras.Sequential([\n",
    "    base_transfer_model_3,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2), #do I need to keep this ?\n",
    "    tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "])\n",
    "\n",
    "#select based on Str\n",
    "if lossSelect == 'normal':\n",
    "    loss_fun_full_fine = tf.keras.losses.CategoricalCrossentropy()\n",
    "else:\n",
    "    loss_fun_full_fine = tf.keras.losses.CategoricalFocalCrossentropy(alpha = focal_alpha,gamma = 2)\n",
    "\n",
    "inception_full_fine_tune_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=loss_fun_full_fine,\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "    #metrics=[\"accuracy\",'precision',]\n",
    "    weighted_metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    ")\n",
    "\n",
    "inception_full_fine_tune_model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_5\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (\u001B[38;5;33mFunctional\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m2048\u001B[0m)     │    \u001B[38;5;34m21,802,784\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)              │        \u001B[38;5;34m12,294\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,294</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m21,815,078\u001B[0m (83.22 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,815,078</span> (83.22 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m21,780,646\u001B[0m (83.09 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,780,646</span> (83.09 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m34,432\u001B[0m (134.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,432</span> (134.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 490
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:10.326156Z",
     "start_time": "2026-01-19T11:22:09.014478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# inception model where layers are sucessively unfrozen during training\n",
    "\n",
    "# Load pre-trained InceptionV3 with correct input size\n",
    "base_transfer_model_4 = tf.keras.applications.InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(target_size[0], target_size[0], 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers except last few blocks\n",
    "base_transfer_model_4.trainable = False\n",
    "#for layer in base_transfer_model_3.layers[:-20]:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# Simple classification head\n",
    "# - GlobalAveragePooling2D reduces spatial dimensions\n",
    "# - Final Dense layer maps to class probabilities\n",
    "inception_multiPhase_fine_tune_model = tf.keras.Sequential([\n",
    "    base_transfer_model_4,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2), #do I need to keep this ?\n",
    "    tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "])\n",
    "\n",
    "#select based on Str\n",
    "if lossSelect == 'normal':\n",
    "    loss_fun_multi_fine = tf.keras.losses.CategoricalCrossentropy()\n",
    "else:\n",
    "    loss_fun_multi_fine = tf.keras.losses.CategoricalFocalCrossentropy(alpha = focal_alpha,gamma = 2)\n",
    "\n",
    "inception_multiPhase_fine_tune_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), #start with \"normal\" learning rate\n",
    "    loss=loss_fun_multi_fine,\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "    #metrics=[\"accuracy\",'precision',]\n",
    "    weighted_metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    ")\n",
    "\n",
    "inception_multiPhase_fine_tune_model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_6\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (\u001B[38;5;33mFunctional\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m2048\u001B[0m)     │    \u001B[38;5;34m21,802,784\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_3      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)              │        \u001B[38;5;34m12,294\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,294</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m21,815,078\u001B[0m (83.22 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,815,078</span> (83.22 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m12,294\u001B[0m (48.02 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,294</span> (48.02 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m21,802,784\u001B[0m (83.17 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> (83.17 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 491
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T17:20:29.792647Z",
     "start_time": "2026-01-19T17:20:28.533768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# inception model where layers are sucessively unfrozen during training - for reduced class Number\n",
    "\n",
    "# Load pre-trained InceptionV3 with correct input size\n",
    "base_transfer_model_5 = tf.keras.applications.InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(target_size[0], target_size[0], 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers except last few blocks\n",
    "base_transfer_model_5.trainable = False\n",
    "#for layer in base_transfer_model_3.layers[:-20]:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# Simple classification head\n",
    "# - GlobalAveragePooling2D reduces spatial dimensions\n",
    "# - Final Dense layer maps to class probabilities\n",
    "inception_multiPhase_redLabel = tf.keras.Sequential([\n",
    "    base_transfer_model_5,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2), #do I need to keep this ?\n",
    "    tf.keras.layers.Dense(num_classes_redLabel, activation = 'softmax')\n",
    "])\n",
    "\n",
    "#select based on Str\n",
    "if lossSelect == 'normal':\n",
    "    loss_fun_multi_redLabel = tf.keras.losses.CategoricalCrossentropy()\n",
    "else:\n",
    "    loss_fun_multi_redLabel = tf.keras.losses.CategoricalFocalCrossentropy(alpha = focal_alpha,gamma = 2)\n",
    "\n",
    "inception_multiPhase_redLabel.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), #start with \"normal\" learning rate\n",
    "    loss=loss_fun_multi_redLabel,\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "    #metrics=[\"accuracy\",'precision',]\n",
    "    weighted_metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    ")\n",
    "\n",
    "inception_multiPhase_redLabel.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (\u001B[38;5;33mFunctional\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m2048\u001B[0m)     │    \u001B[38;5;34m21,802,784\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m)              │         \u001B[38;5;34m6,147\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,147</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m21,808,931\u001B[0m (83.19 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,808,931</span> (83.19 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m6,147\u001B[0m (24.01 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,147</span> (24.01 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m21,802,784\u001B[0m (83.17 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> (83.17 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 587
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T14:47:37.418032Z",
     "start_time": "2026-01-20T14:47:36.985738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# EfficientNet model where layers are sucessively unfrozen during training\n",
    "\n",
    "# Load pre-trained InceptionV3 with correct input size\n",
    "base_model_efficientNet = tf.keras.applications.EfficientNetV2S(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    include_preprocessing=True,\n",
    "    input_shape=(target_size[0], target_size[0], 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers except last few blocks\n",
    "base_model_efficientNet.trainable = False\n",
    "#for layer in base_transfer_model_3.layers[:-20]:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# Simple classification head\n",
    "# - GlobalAveragePooling2D reduces spatial dimensions\n",
    "# - Final Dense layer maps to class probabilities\n",
    "EfficientNet_multiPhase_model = tf.keras.Sequential([\n",
    "    base_model_efficientNet,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2), #do I need to keep this ?\n",
    "    tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "])\n",
    "\n",
    "#select based on Str\n",
    "if lossSelect == 'normal':\n",
    "    loss_fun_EfficientNet = tf.keras.losses.CategoricalCrossentropy()\n",
    "else:\n",
    "    loss_fun_EfficientNet = tf.keras.losses.CategoricalFocalCrossentropy(alpha = focal_alpha,gamma = 2)\n",
    "\n",
    "inception_multiPhase_fine_tune_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), #start with \"normal\" learning rate\n",
    "    loss=loss_fun_EfficientNet,\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "    #metrics=[\"accuracy\",'precision',]\n",
    "    weighted_metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    ")\n",
    "\n",
    "EfficientNet_multiPhase_model.summary()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# EfficientNet model where layers are sucessively unfrozen during training\u001B[39;00m\n\u001B[32m      2\u001B[39m \n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# Load pre-trained InceptionV3 with correct input size\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m base_model_efficientNet = \u001B[43mtf\u001B[49m.keras.applications.EfficientNetV2S(\n\u001B[32m      5\u001B[39m     weights=\u001B[33m'\u001B[39m\u001B[33mimagenet\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m      6\u001B[39m     include_top=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m      7\u001B[39m     include_preprocessing=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m      8\u001B[39m     input_shape=(target_size[\u001B[32m0\u001B[39m], target_size[\u001B[32m0\u001B[39m], \u001B[32m3\u001B[39m)\n\u001B[32m      9\u001B[39m )\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m# Freeze all layers except last few blocks\u001B[39;00m\n\u001B[32m     12\u001B[39m base_model_efficientNet.trainable = \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'tf' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:10.359514Z",
     "start_time": "2026-01-19T11:22:10.344154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compile Models\n",
    "\n",
    "#select based on Str\n",
    "if lossSelect == 'normal':\n",
    "    loss_fun_1 = tf.keras.losses.CategoricalCrossentropy()\n",
    "else:\n",
    "    loss_fun_1 = tf.keras.losses.CategoricalFocalCrossentropy(alpha = focal_alpha,gamma = 2)\n",
    "\n",
    "model_1_CNN.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learningRate),\n",
    "    loss=loss_fun_1,\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "    #metrics=[\"accuracy\",'precision',]\n",
    "    weighted_metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    ")\n",
    "\n",
    "#select based on Str\n",
    "if lossSelect == 'normal':\n",
    "    loss_fun_2 = tf.keras.losses.CategoricalCrossentropy()\n",
    "else:\n",
    "    loss_fun_2 = tf.keras.losses.CategoricalFocalCrossentropy(alpha = focal_alpha,gamma = 2)\n",
    "\n",
    "model_2_CNN.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learningRate),\n",
    "    loss=loss_fun_2,\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "    #metrics=[\"accuracy\",'precision',]\n",
    "    weighted_metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    ")\n",
    "\n",
    "#select based on Str\n",
    "if lossSelect == 'normal':\n",
    "    loss_fun_3 = tf.keras.losses.CategoricalCrossentropy()\n",
    "else:\n",
    "    loss_fun_3 = tf.keras.losses.CategoricalFocalCrossentropy(alpha = focal_alpha,gamma = 2)\n",
    "\n",
    "model_3_CNN.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learningRate),\n",
    "    loss=loss_fun_3,\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "    #metrics=[\"accuracy\",'precision',]\n",
    "    #metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    "    weighted_metrics =[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    ")\n",
    "\n",
    "#F1 average parameter needs to be anything other than None if using linewise output when fiting the model...\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 492
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:10.369908Z",
     "start_time": "2026-01-19T11:22:10.364509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#select model datasets based on flags\n",
    "\n",
    "#for model1 - 3\n",
    "if balanced_flag:\n",
    "    CNN_model_val_gen = train_generator_val\n",
    "    if aug_flag:\n",
    "        CNN_model_gen = train_generator_aug\n",
    "    else:\n",
    "        CNN_model_gen = train_generator\n",
    "    #class weights\n",
    "    class_weights_training = class_weights_b\n",
    "else:\n",
    "    CNN_model_val_gen = train_generator_unbalanced_val\n",
    "    if aug_flag:\n",
    "        CNN_model_gen = train_generator_unbalanced_aug\n",
    "    else:\n",
    "        CNN_model_gen = train_generator_unbalanced\n",
    "\n",
    "#for transfer learning\n",
    "if balanced_flag:\n",
    "    transfer_model_val_gen = train_generator_val_color\n",
    "    if aug_flag:\n",
    "        transfer_model_gen = train_generator_aug_color\n",
    "    else:\n",
    "        transfer_model_gen = train_generator_color\n",
    "else:\n",
    "    transfer_model_val_gen = train_generator_unbalanced_val_color\n",
    "    if aug_flag:\n",
    "        transfer_model_gen = train_generator_unbalanced_aug_color\n",
    "    else:\n",
    "        transfer_model_gen = train_generator_unbalanced_color\n",
    "\n",
    "\n",
    "if Use_class_weights:\n",
    "    if balanced_flag:\n",
    "        class_weights_training = class_w_b_dict\n",
    "    else:\n",
    "        class_weights_training = class_w_unb_dict\n",
    "else:\n",
    "    class_weights_training = class_w_equal_dict\n"
   ],
   "outputs": [],
   "execution_count": 493
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:10.380197Z",
     "start_time": "2026-01-19T11:22:10.376907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if model1_flag:\n",
    "\n",
    "    history_1 = model_1_CNN.fit(\n",
    "    CNN_model_gen,\n",
    "    validation_data = CNN_model_val_gen,\n",
    "    epochs=max_epochs,\n",
    "    class_weight = class_weights_training,\n",
    "    callbacks=[StopCallback,ResetValLossOnTrainBegin()],\n",
    "    verbose = 2 #2 is one line per epoch -\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 494
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:10.390254Z",
     "start_time": "2026-01-19T11:22:10.386199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model 2\n",
    "\n",
    "if model2_flag:\n",
    "    history_2 = model_2_CNN.fit(\n",
    "        CNN_model_gen,\n",
    "        validation_data = CNN_model_val_gen,\n",
    "        epochs=max_epochs,\n",
    "        class_weight = class_weights_training,\n",
    "        callbacks=[StopCallback,ResetValLossOnTrainBegin()],\n",
    "        verbose = 2 #2 is one line per epoch -\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 495
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:10.398655Z",
     "start_time": "2026-01-19T11:22:10.395257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model 3\n",
    "\n",
    "if model3_flag:\n",
    "    # model_3_CNN.fit(\n",
    "    #     CNN_model_gen,\n",
    "    #     validation_data = CNN_model_val_gen,\n",
    "    #     epochs=3,\n",
    "    #     class_weight = class_weights_training,\n",
    "    #     callbacks=[StopCallback,ResetValLossOnTrainBegin()],\n",
    "    #     verbose = 2 #2 is one line per epoch -\n",
    "    # )\n",
    "\n",
    "    history_3 = model_3_CNN.fit(\n",
    "        CNN_model_gen,\n",
    "        validation_data = CNN_model_val_gen,\n",
    "        epochs=max_epochs,\n",
    "        class_weight = class_weights_training,\n",
    "        callbacks=[StopCallback,ResetValLossOnTrainBegin()],\n",
    "        verbose = 2 #2 is one line per epoch -\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 496
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:10.407546Z",
     "start_time": "2026-01-19T11:22:10.403659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#transfer learning. Feature extraction\n",
    "\n",
    "if feature_extract_flag:\n",
    "    history_feat_extract = inception_feature_extraction_model.fit(\n",
    "        transfer_model_gen,\n",
    "        validation_data = transfer_model_val_gen,\n",
    "        epochs=max_epochs,\n",
    "        class_weight = class_weights_training,\n",
    "        callbacks=[StopCallback,ResetValLossOnTrainBegin()],\n",
    "        verbose = 2 #2 is one line per epoch -\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 497
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:10.416629Z",
     "start_time": "2026-01-19T11:22:10.412550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#transfer learning. fine tuning\n",
    "\n",
    "if fine_tune_flag:\n",
    "    # inception_fine_tune_model.fit(\n",
    "    #     transfer_model_gen,\n",
    "    #     validation_data = transfer_model_val_gen,\n",
    "    #     epochs=3,\n",
    "    #     class_weight = class_weights_training,\n",
    "    #     callbacks=[StopCallback,ResetValLossOnTrainBegin()],\n",
    "    #     verbose = 2 #2 is one line per epoch -\n",
    "    # )\n",
    "\n",
    "    history_fine_tune = inception_fine_tune_model.fit(\n",
    "        transfer_model_gen,\n",
    "        validation_data = transfer_model_val_gen,\n",
    "        epochs=max_epochs,\n",
    "        class_weight = class_weights_training,\n",
    "        callbacks=[StopCallback,ResetValLossOnTrainBegin()],\n",
    "        verbose = 2 #2 is one line per epoch -\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 498
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:22:10.425836Z",
     "start_time": "2026-01-19T11:22:10.421632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# transfer learning. fine tuning of full model\n",
    "# propably make a scheduler for the learning rate.\n",
    "# Also - train model sucessively\n",
    "\n",
    "if full_fine_tune_flag:\n",
    "    # inception_fine_tune_model.fit(\n",
    "    #     transfer_model_gen,\n",
    "    #     validation_data = transfer_model_val_gen,\n",
    "    #     epochs=3,\n",
    "    #     class_weight = class_weights_training,\n",
    "    #     callbacks=[StopCallback,ResetValLossOnTrainBegin()],\n",
    "    #     verbose = 2 #2 is one line per epoch -\n",
    "    # )\n",
    "\n",
    "    history_full_fine_tune = inception_full_fine_tune_model.fit(\n",
    "        transfer_model_gen,\n",
    "        validation_data = transfer_model_val_gen,\n",
    "        epochs=max_epochs,\n",
    "        class_weight = class_weights_training,\n",
    "        callbacks=[StopCallback,ResetValLossOnTrainBegin()],\n",
    "        verbose = 2 #2 is one line per epoch -\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 499
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:55:28.224390Z",
     "start_time": "2026-01-19T11:22:10.430840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# transfer learning. fine tuning of full model\n",
    "# multi phase fine tuning\n",
    "\n",
    "#delete history if it already exists to unsure expected local stopping behaviour\n",
    "if 'history_multi_fine_tune' in locals():\n",
    "    del history_multi_fine_tune\n",
    "\n",
    "if multi_phase_fine_tune_flag:\n",
    "\n",
    "    match StoppingSelector:\n",
    "        case 'val_loss':\n",
    "            StopCallback_multi = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.01,\n",
    "                patience= loss_stop_patience_multi[0],\n",
    "                restore_best_weights=True,\n",
    "                verbose = 2,\n",
    "                start_from_epoch = 1\n",
    "            )\n",
    "        case 'val_f1':\n",
    "            StopCallback_multi = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_f1_score',\n",
    "                min_delta=0.005,\n",
    "                patience= loss_stop_patience_multi[0],\n",
    "                restore_best_weights=True,\n",
    "                verbose = 2,\n",
    "                mode='max'\n",
    "            )\n",
    "\n",
    "    # train last layer first\n",
    "    history_multi_fine_tune = inception_multiPhase_fine_tune_model.fit(\n",
    "        transfer_model_gen,\n",
    "        validation_data = transfer_model_val_gen,\n",
    "        epochs=max_epochs,\n",
    "        class_weight = class_weights_training,\n",
    "        callbacks=[StopCallback_multi],\n",
    "        verbose = 2 #2 is one line per epoch -\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "166/166 - 285s - 2s/step - accuracy: 0.5636 - f1_score: 0.5589 - loss: 1.1622 - precision: 0.7397 - recall: 0.3864 - val_accuracy: 0.9245 - val_f1_score: 0.9371 - val_loss: 0.2092 - val_precision: 0.9627 - val_recall: 0.8965\n",
      "Epoch 2/100\n",
      "166/166 - 245s - 1s/step - accuracy: 0.7637 - f1_score: 0.7631 - loss: 0.6516 - precision: 0.8191 - recall: 0.6805 - val_accuracy: 0.5627 - val_f1_score: 0.6664 - val_loss: 1.2084 - val_precision: 0.5729 - val_recall: 0.4275\n",
      "Epoch 3/100\n",
      "166/166 - 244s - 1s/step - accuracy: 0.8291 - f1_score: 0.8285 - loss: 0.5151 - precision: 0.8657 - recall: 0.7511 - val_accuracy: 0.9698 - val_f1_score: 0.9713 - val_loss: 0.1221 - val_precision: 0.9815 - val_recall: 0.9607\n",
      "Epoch 4/100\n",
      "166/166 - 244s - 1s/step - accuracy: 0.8357 - f1_score: 0.8356 - loss: 0.4729 - precision: 0.8791 - recall: 0.7994 - val_accuracy: 0.9690 - val_f1_score: 0.9719 - val_loss: 0.0863 - val_precision: 0.9808 - val_recall: 0.9653\n",
      "Epoch 5/100\n",
      "166/166 - 245s - 1s/step - accuracy: 0.8263 - f1_score: 0.8254 - loss: 0.4562 - precision: 0.8773 - recall: 0.8087 - val_accuracy: 0.8550 - val_f1_score: 0.9039 - val_loss: 0.3360 - val_precision: 0.8680 - val_recall: 0.8444\n",
      "Epoch 6/100\n",
      "166/166 - 244s - 1s/step - accuracy: 0.8603 - f1_score: 0.8603 - loss: 0.3870 - precision: 0.8987 - recall: 0.8145 - val_accuracy: 0.8860 - val_f1_score: 0.9191 - val_loss: 0.2273 - val_precision: 0.9032 - val_recall: 0.8739\n",
      "Epoch 7/100\n",
      "166/166 - 245s - 1s/step - accuracy: 0.8501 - f1_score: 0.8492 - loss: 0.3572 - precision: 0.8858 - recall: 0.8312 - val_accuracy: 0.9683 - val_f1_score: 0.9711 - val_loss: 0.0910 - val_precision: 0.9838 - val_recall: 0.9622\n",
      "Epoch 8/100\n",
      "166/166 - 244s - 1s/step - accuracy: 0.8710 - f1_score: 0.8705 - loss: 0.3547 - precision: 0.8903 - recall: 0.8431 - val_accuracy: 0.8520 - val_f1_score: 0.8975 - val_loss: 0.3524 - val_precision: 0.8640 - val_recall: 0.8399\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n"
     ]
    }
   ],
   "execution_count": 500
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:38:10.537109Z",
     "start_time": "2026-01-19T11:55:28.286507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if multi_phase_fine_tune_flag:\n",
    "    #delete old history to avoid early stopping unexpected behaviour\n",
    "    del history_multi_fine_tune\n",
    "\n",
    "    #set last 30 layers to be trainable\n",
    "    for layer in base_transfer_model_4.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    match StoppingSelector:\n",
    "        case 'val_loss':\n",
    "            StopCallback_multi = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.01,\n",
    "                patience= loss_stop_patience_multi[1],\n",
    "                restore_best_weights=True,\n",
    "                verbose = 2,\n",
    "                start_from_epoch = 1\n",
    "            )\n",
    "        case 'val_f1':\n",
    "            StopCallback_multi = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_f1_score',\n",
    "                min_delta=0.005,\n",
    "                patience= loss_stop_patience_multi[1],\n",
    "                restore_best_weights=True,\n",
    "                verbose = 2,\n",
    "                mode='max'\n",
    "            )\n",
    "\n",
    "    inception_multiPhase_fine_tune_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), #go to lower learning rate\n",
    "        loss=loss_fun_multi_fine,\n",
    "        #loss=tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "        #metrics=[\"accuracy\",'precision',]\n",
    "        weighted_metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    "    )\n",
    "\n",
    "    history_multi_fine_tune = inception_multiPhase_fine_tune_model.fit(\n",
    "        transfer_model_gen,\n",
    "        validation_data = transfer_model_val_gen,\n",
    "        epochs=max_epochs,\n",
    "        class_weight = class_weights_training,\n",
    "        callbacks=[StopCallback_multi,ResetValLossOnTrainBegin()],\n",
    "        verbose = 2 #2 is one line per epoch -\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "166/166 - 297s - 2s/step - accuracy: 0.7466 - f1_score: 0.7460 - loss: 0.8215 - precision: 0.7688 - recall: 0.7232 - val_accuracy: 0.9766 - val_f1_score: 0.9803 - val_loss: 0.0759 - val_precision: 0.9780 - val_recall: 0.9728\n",
      "Epoch 2/100\n",
      "166/166 - 291s - 2s/step - accuracy: 0.8727 - f1_score: 0.8724 - loss: 0.3748 - precision: 0.8911 - recall: 0.8541 - val_accuracy: 0.9834 - val_f1_score: 0.9841 - val_loss: 0.0509 - val_precision: 0.9871 - val_recall: 0.9796\n",
      "Epoch 3/100\n",
      "166/166 - 284s - 2s/step - accuracy: 0.8833 - f1_score: 0.8829 - loss: 0.3150 - precision: 0.8889 - recall: 0.8705 - val_accuracy: 0.9902 - val_f1_score: 0.9907 - val_loss: 0.0323 - val_precision: 0.9917 - val_recall: 0.9887\n",
      "Epoch 4/100\n",
      "166/166 - 297s - 2s/step - accuracy: 0.9092 - f1_score: 0.9092 - loss: 0.2218 - precision: 0.9170 - recall: 0.9041 - val_accuracy: 0.9879 - val_f1_score: 0.9877 - val_loss: 0.0379 - val_precision: 0.9886 - val_recall: 0.9856\n",
      "Epoch 5/100\n",
      "166/166 - 284s - 2s/step - accuracy: 0.9276 - f1_score: 0.9277 - loss: 0.2228 - precision: 0.9367 - recall: 0.9230 - val_accuracy: 0.9018 - val_f1_score: 0.9404 - val_loss: 0.1746 - val_precision: 0.9023 - val_recall: 0.9003\n",
      "Epoch 6/100\n",
      "166/166 - 281s - 2s/step - accuracy: 0.9231 - f1_score: 0.9231 - loss: 0.1906 - precision: 0.9271 - recall: 0.9161 - val_accuracy: 0.8920 - val_f1_score: 0.9322 - val_loss: 0.1773 - val_precision: 0.8939 - val_recall: 0.8905\n",
      "Epoch 7/100\n",
      "166/166 - 276s - 2s/step - accuracy: 0.9330 - f1_score: 0.9329 - loss: 0.1707 - precision: 0.9350 - recall: 0.9278 - val_accuracy: 0.9917 - val_f1_score: 0.9917 - val_loss: 0.0279 - val_precision: 0.9924 - val_recall: 0.9909\n",
      "Epoch 8/100\n",
      "166/166 - 275s - 2s/step - accuracy: 0.9492 - f1_score: 0.9489 - loss: 0.1433 - precision: 0.9514 - recall: 0.9377 - val_accuracy: 0.9260 - val_f1_score: 0.9548 - val_loss: 0.1175 - val_precision: 0.9266 - val_recall: 0.9245\n",
      "Epoch 9/100\n",
      "166/166 - 275s - 2s/step - accuracy: 0.9298 - f1_score: 0.9298 - loss: 0.1933 - precision: 0.9313 - recall: 0.9281 - val_accuracy: 0.9139 - val_f1_score: 0.9450 - val_loss: 0.1537 - val_precision: 0.9137 - val_recall: 0.9116\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n"
     ]
    }
   ],
   "execution_count": 501
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:32:42.383722Z",
     "start_time": "2026-01-19T12:38:10.600125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if multi_phase_fine_tune_flag:\n",
    "\n",
    "    match StoppingSelector:\n",
    "        case 'val_loss':\n",
    "            StopCallback_multi = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.01,\n",
    "                patience= loss_stop_patience_multi[2],\n",
    "                restore_best_weights=True,\n",
    "                verbose = 2,\n",
    "                start_from_epoch = 1\n",
    "            )\n",
    "        case 'val_f1':\n",
    "            StopCallback_multi = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_f1_score',\n",
    "                min_delta=0.005,\n",
    "                patience= loss_stop_patience_multi[2],\n",
    "                restore_best_weights=True,\n",
    "                verbose = 2,\n",
    "                mode='max'\n",
    "            )\n",
    "\n",
    "    #delete old history to avoid early stopping unexpected behaviour\n",
    "    del history_multi_fine_tune\n",
    "\n",
    "    #set last 100 layers to trainable\n",
    "    for layer in base_transfer_model_4.layers[-100:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    inception_multiPhase_fine_tune_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), #go to lower learning rate\n",
    "        loss=loss_fun_multi_fine,\n",
    "        #loss=tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "        #metrics=[\"accuracy\",'precision',]\n",
    "        weighted_metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    "    )\n",
    "\n",
    "    history_multi_fine_tune = inception_multiPhase_fine_tune_model.fit(\n",
    "        transfer_model_gen,\n",
    "        validation_data = transfer_model_val_gen,\n",
    "        epochs=max_epochs,\n",
    "        class_weight = class_weights_training,\n",
    "        callbacks=[StopCallback_multi,ResetValLossOnTrainBegin()],\n",
    "        verbose = 2 #2 is one line per epoch -\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "166/166 - 373s - 2s/step - accuracy: 0.8879 - f1_score: 0.8874 - loss: 0.3242 - precision: 0.8966 - recall: 0.8824 - val_accuracy: 0.9864 - val_f1_score: 0.9875 - val_loss: 0.0588 - val_precision: 0.9864 - val_recall: 0.9864\n",
      "Epoch 2/100\n",
      "166/166 - 360s - 2s/step - accuracy: 0.9203 - f1_score: 0.9206 - loss: 0.2242 - precision: 0.9226 - recall: 0.9126 - val_accuracy: 0.9902 - val_f1_score: 0.9907 - val_loss: 0.0342 - val_precision: 0.9909 - val_recall: 0.9894\n",
      "Epoch 3/100\n",
      "166/166 - 360s - 2s/step - accuracy: 0.9578 - f1_score: 0.9578 - loss: 0.1253 - precision: 0.9602 - recall: 0.9520 - val_accuracy: 0.9864 - val_f1_score: 0.9873 - val_loss: 0.0426 - val_precision: 0.9879 - val_recall: 0.9864\n",
      "Epoch 4/100\n",
      "166/166 - 361s - 2s/step - accuracy: 0.9501 - f1_score: 0.9500 - loss: 0.1643 - precision: 0.9508 - recall: 0.9475 - val_accuracy: 0.9751 - val_f1_score: 0.9817 - val_loss: 0.0639 - val_precision: 0.9780 - val_recall: 0.9721\n",
      "Epoch 5/100\n",
      "166/166 - 361s - 2s/step - accuracy: 0.9383 - f1_score: 0.9384 - loss: 0.1618 - precision: 0.9405 - recall: 0.9350 - val_accuracy: 0.9924 - val_f1_score: 0.9927 - val_loss: 0.0264 - val_precision: 0.9932 - val_recall: 0.9924\n",
      "Epoch 6/100\n",
      "166/166 - 364s - 2s/step - accuracy: 0.9607 - f1_score: 0.9607 - loss: 0.1048 - precision: 0.9626 - recall: 0.9580 - val_accuracy: 0.9924 - val_f1_score: 0.9927 - val_loss: 0.0435 - val_precision: 0.9932 - val_recall: 0.9902\n",
      "Epoch 7/100\n",
      "166/166 - 361s - 2s/step - accuracy: 0.9703 - f1_score: 0.9703 - loss: 0.0922 - precision: 0.9707 - recall: 0.9701 - val_accuracy: 0.9977 - val_f1_score: 0.9978 - val_loss: 0.0238 - val_precision: 0.9977 - val_recall: 0.9977\n",
      "Epoch 8/100\n",
      "166/166 - 361s - 2s/step - accuracy: 0.9782 - f1_score: 0.9782 - loss: 0.0542 - precision: 0.9789 - recall: 0.9779 - val_accuracy: 0.9902 - val_f1_score: 0.9903 - val_loss: 0.0412 - val_precision: 0.9902 - val_recall: 0.9902\n",
      "Epoch 9/100\n",
      "166/166 - 361s - 2s/step - accuracy: 0.9870 - f1_score: 0.9870 - loss: 0.0357 - precision: 0.9872 - recall: 0.9859 - val_accuracy: 0.9894 - val_f1_score: 0.9898 - val_loss: 0.0464 - val_precision: 0.9894 - val_recall: 0.9894\n",
      "Epoch 10/100\n",
      "166/166 - 360s - 2s/step - accuracy: 0.9860 - f1_score: 0.9860 - loss: 0.0421 - precision: 0.9862 - recall: 0.9860 - val_accuracy: 0.9924 - val_f1_score: 0.9926 - val_loss: 0.0295 - val_precision: 0.9924 - val_recall: 0.9924\n",
      "Epoch 11/100\n",
      "166/166 - 360s - 2s/step - accuracy: 0.9897 - f1_score: 0.9897 - loss: 0.0295 - precision: 0.9897 - recall: 0.9896 - val_accuracy: 0.9872 - val_f1_score: 0.9877 - val_loss: 0.0518 - val_precision: 0.9872 - val_recall: 0.9872\n",
      "Epoch 12/100\n",
      "166/166 - 360s - 2s/step - accuracy: 0.9686 - f1_score: 0.9686 - loss: 0.1122 - precision: 0.9687 - recall: 0.9672 - val_accuracy: 0.9955 - val_f1_score: 0.9955 - val_loss: 0.0355 - val_precision: 0.9970 - val_recall: 0.9955\n",
      "Epoch 13/100\n",
      "166/166 - 360s - 2s/step - accuracy: 0.9721 - f1_score: 0.9721 - loss: 0.0763 - precision: 0.9735 - recall: 0.9713 - val_accuracy: 0.9887 - val_f1_score: 0.9890 - val_loss: 0.0419 - val_precision: 0.9894 - val_recall: 0.9887\n",
      "Epoch 14/100\n",
      "166/166 - 361s - 2s/step - accuracy: 0.9848 - f1_score: 0.9849 - loss: 0.0501 - precision: 0.9850 - recall: 0.9809 - val_accuracy: 0.9018 - val_f1_score: 0.9407 - val_loss: 0.1458 - val_precision: 0.9018 - val_recall: 0.9018\n",
      "Epoch 15/100\n",
      "166/166 - 362s - 2s/step - accuracy: 0.9858 - f1_score: 0.9858 - loss: 0.0343 - precision: 0.9858 - recall: 0.9858 - val_accuracy: 0.9970 - val_f1_score: 0.9970 - val_loss: 0.0305 - val_precision: 0.9970 - val_recall: 0.9962\n",
      "Epoch 16/100\n",
      "166/166 - 361s - 2s/step - accuracy: 0.9922 - f1_score: 0.9922 - loss: 0.0320 - precision: 0.9933 - recall: 0.9922 - val_accuracy: 0.9917 - val_f1_score: 0.9930 - val_loss: 0.0366 - val_precision: 0.9924 - val_recall: 0.9909\n",
      "Epoch 17/100\n",
      "166/166 - 361s - 2s/step - accuracy: 0.9838 - f1_score: 0.9838 - loss: 0.0526 - precision: 0.9841 - recall: 0.9834 - val_accuracy: 0.9955 - val_f1_score: 0.9956 - val_loss: 0.0161 - val_precision: 0.9955 - val_recall: 0.9947\n",
      "Epoch 18/100\n",
      "166/166 - 361s - 2s/step - accuracy: 0.9876 - f1_score: 0.9876 - loss: 0.0423 - precision: 0.9877 - recall: 0.9871 - val_accuracy: 0.9796 - val_f1_score: 0.9850 - val_loss: 0.0591 - val_precision: 0.9803 - val_recall: 0.9781\n",
      "Epoch 19/100\n",
      "166/166 - 361s - 2s/step - accuracy: 0.9847 - f1_score: 0.9847 - loss: 0.0570 - precision: 0.9857 - recall: 0.9844 - val_accuracy: 0.9924 - val_f1_score: 0.9930 - val_loss: 0.0189 - val_precision: 0.9932 - val_recall: 0.9924\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    }
   ],
   "execution_count": 502
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T17:58:48.410036Z",
     "start_time": "2026-01-19T17:20:42.447379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#train fine tuning model with reduced number of label classes\n",
    "\n",
    "if 'history_multi_redLabel' in locals():\n",
    "    del history_multi_redLabel\n",
    "\n",
    "if reducedClassNumber_flag:\n",
    "\n",
    "    match StoppingSelector:\n",
    "        case 'val_loss':\n",
    "            StopCallback_redLabel = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.01,\n",
    "                patience= loss_stop_patience_multi[0],\n",
    "                restore_best_weights=True,\n",
    "                verbose = 2,\n",
    "                start_from_epoch = 1\n",
    "            )\n",
    "        case 'val_f1':\n",
    "            StopCallback_redLabel = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_f1_score',\n",
    "                min_delta=0.005,\n",
    "                patience= loss_stop_patience_multi[0],\n",
    "                restore_best_weights=True,\n",
    "                verbose = 2,\n",
    "                mode='max'\n",
    "            )\n",
    "\n",
    "    # train last layer first\n",
    "    history_multi_redLabel = inception_multiPhase_redLabel.fit(\n",
    "        train_generator_redLabel_aug,\n",
    "        validation_data = train_generator_redLabel_val,\n",
    "        epochs=max_epochs,\n",
    "        class_weight = class_weights_redLabel_dict,\n",
    "        callbacks=[StopCallback_redLabel],\n",
    "        verbose = 2 #2 is one line per epoch -\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "166/166 - 280s - 2s/step - accuracy: 0.7742 - f1_score: 0.7741 - loss: 0.6075 - precision: 0.8065 - recall: 0.7583 - val_accuracy: 0.9381 - val_f1_score: 0.9424 - val_loss: 0.1852 - val_precision: 0.9407 - val_recall: 0.9343\n",
      "Epoch 2/100\n",
      "166/166 - 269s - 2s/step - accuracy: 0.8846 - f1_score: 0.8846 - loss: 0.3349 - precision: 0.8960 - recall: 0.8786 - val_accuracy: 0.8882 - val_f1_score: 0.9180 - val_loss: 0.2656 - val_precision: 0.8946 - val_recall: 0.8784\n",
      "Epoch 3/100\n",
      "166/166 - 248s - 1s/step - accuracy: 0.8923 - f1_score: 0.8924 - loss: 0.2852 - precision: 0.9024 - recall: 0.8872 - val_accuracy: 0.9396 - val_f1_score: 0.9466 - val_loss: 0.2014 - val_precision: 0.9408 - val_recall: 0.9366\n",
      "Epoch 4/100\n",
      "166/166 - 249s - 2s/step - accuracy: 0.8944 - f1_score: 0.8945 - loss: 0.2664 - precision: 0.8953 - recall: 0.8916 - val_accuracy: 0.9502 - val_f1_score: 0.9563 - val_loss: 0.1386 - val_precision: 0.9523 - val_recall: 0.9494\n",
      "Epoch 5/100\n",
      "166/166 - 249s - 1s/step - accuracy: 0.9257 - f1_score: 0.9257 - loss: 0.2062 - precision: 0.9288 - recall: 0.9248 - val_accuracy: 0.8573 - val_f1_score: 0.8955 - val_loss: 0.2859 - val_precision: 0.8614 - val_recall: 0.8542\n",
      "Epoch 6/100\n",
      "166/166 - 248s - 1s/step - accuracy: 0.9355 - f1_score: 0.9354 - loss: 0.2090 - precision: 0.9381 - recall: 0.9336 - val_accuracy: 0.9215 - val_f1_score: 0.9378 - val_loss: 0.1891 - val_precision: 0.9270 - val_recall: 0.9207\n",
      "Epoch 7/100\n",
      "166/166 - 247s - 1s/step - accuracy: 0.9520 - f1_score: 0.9519 - loss: 0.1606 - precision: 0.9526 - recall: 0.9430 - val_accuracy: 0.9199 - val_f1_score: 0.9396 - val_loss: 0.1660 - val_precision: 0.9219 - val_recall: 0.9184\n",
      "Epoch 8/100\n",
      "166/166 - 247s - 1s/step - accuracy: 0.9223 - f1_score: 0.9224 - loss: 0.2348 - precision: 0.9236 - recall: 0.9140 - val_accuracy: 0.9411 - val_f1_score: 0.9459 - val_loss: 0.1919 - val_precision: 0.9425 - val_recall: 0.9411\n",
      "Epoch 9/100\n",
      "166/166 - 248s - 1s/step - accuracy: 0.9386 - f1_score: 0.9386 - loss: 0.1705 - precision: 0.9400 - recall: 0.9296 - val_accuracy: 0.9441 - val_f1_score: 0.9514 - val_loss: 0.1632 - val_precision: 0.9476 - val_recall: 0.9434\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    }
   ],
   "execution_count": 588
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T19:40:40.368677Z",
     "start_time": "2026-01-19T19:20:06.634683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if reducedClassNumber_flag:\n",
    "\n",
    "    del history_multi_redLabel\n",
    "\n",
    "    match StoppingSelector:\n",
    "        case 'val_loss':\n",
    "            StopCallback_redLabel = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.01,\n",
    "                patience= loss_stop_patience_multi[1],\n",
    "                restore_best_weights=True,\n",
    "                verbose = 2,\n",
    "                start_from_epoch = 1\n",
    "            )\n",
    "        case 'val_f1':\n",
    "            StopCallback_redLabel = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_f1_score',\n",
    "                min_delta=0.005,\n",
    "                patience= loss_stop_patience_multi[1],\n",
    "                restore_best_weights=True,\n",
    "                verbose = 2,\n",
    "                mode='max'\n",
    "            )\n",
    "\n",
    "    #set last 30 layers to be trainable\n",
    "    for layer in base_transfer_model_5.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    inception_multiPhase_redLabel.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), #go to lower learning rate\n",
    "        loss=loss_fun_multi_redLabel,\n",
    "        weighted_metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    "    )\n",
    "\n",
    "    history_multi_redLabel = inception_multiPhase_redLabel.fit(\n",
    "        train_generator_redLabel_aug,\n",
    "        validation_data = train_generator_redLabel_val,\n",
    "        epochs=max_epochs,\n",
    "        class_weight = class_weights_redLabel_dict,\n",
    "        callbacks=[StopCallback_redLabel],\n",
    "        verbose = 2 #2 is one line per epoch -\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "166/166 - 333s - 2s/step - accuracy: 0.8353 - f1_score: 0.8342 - loss: 0.6487 - precision: 0.8424 - recall: 0.8350 - val_accuracy: 0.9653 - val_f1_score: 0.9628 - val_loss: 0.1204 - val_precision: 0.9653 - val_recall: 0.9653\n",
      "Epoch 2/100\n",
      "166/166 - 314s - 2s/step - accuracy: 0.9197 - f1_score: 0.9196 - loss: 0.2680 - precision: 0.9210 - recall: 0.9189 - val_accuracy: 0.9622 - val_f1_score: 0.9651 - val_loss: 0.1113 - val_precision: 0.9622 - val_recall: 0.9607\n",
      "Epoch 3/100\n",
      "166/166 - 313s - 2s/step - accuracy: 0.9319 - f1_score: 0.9319 - loss: 0.2434 - precision: 0.9332 - recall: 0.9312 - val_accuracy: 0.9690 - val_f1_score: 0.9714 - val_loss: 0.1161 - val_precision: 0.9697 - val_recall: 0.9683\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[589]\u001B[39m\u001B[32m, line 35\u001B[39m\n\u001B[32m     27\u001B[39m     layer.trainable = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     29\u001B[39m inception_multiPhase_redLabel.compile(\n\u001B[32m     30\u001B[39m     optimizer=tf.keras.optimizers.Adam(learning_rate=\u001B[32m1e-3\u001B[39m), \u001B[38;5;66;03m#go to lower learning rate\u001B[39;00m\n\u001B[32m     31\u001B[39m     loss=loss_fun_multi_redLabel,\n\u001B[32m     32\u001B[39m     weighted_metrics=[\u001B[33m\"\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m\"\u001B[39m,\u001B[33m'\u001B[39m\u001B[33mprecision\u001B[39m\u001B[33m'\u001B[39m,\u001B[33m'\u001B[39m\u001B[33mrecall\u001B[39m\u001B[33m'\u001B[39m,tf.keras.metrics.F1Score(average=\u001B[33m'\u001B[39m\u001B[33mweighted\u001B[39m\u001B[33m'\u001B[39m)]\n\u001B[32m     33\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m history_multi_redLabel = \u001B[43minception_multiPhase_redLabel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     36\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_generator_redLabel_aug\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_generator_redLabel_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     38\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     39\u001B[39m \u001B[43m    \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_weights_redLabel_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mStopCallback_redLabel\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     41\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m#2 is one line per epoch -\u001B[39;49;00m\n\u001B[32m     42\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    115\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    116\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:423\u001B[39m, in \u001B[36mTensorFlowTrainer.fit\u001B[39m\u001B[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[39m\n\u001B[32m    412\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m_eval_epoch_iterator\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    413\u001B[39m     \u001B[38;5;28mself\u001B[39m._eval_epoch_iterator = TFEpochIterator(\n\u001B[32m    414\u001B[39m         x=val_x,\n\u001B[32m    415\u001B[39m         y=val_y,\n\u001B[32m   (...)\u001B[39m\u001B[32m    421\u001B[39m         shuffle=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    422\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m423\u001B[39m val_logs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    424\u001B[39m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m=\u001B[49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    425\u001B[39m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m=\u001B[49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    426\u001B[39m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    427\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    428\u001B[39m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    429\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    430\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    431\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    432\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    433\u001B[39m val_logs = {\n\u001B[32m    434\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mval_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs.items()\n\u001B[32m    435\u001B[39m }\n\u001B[32m    436\u001B[39m epoch_logs.update(val_logs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    115\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    116\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:511\u001B[39m, in \u001B[36mTensorFlowTrainer.evaluate\u001B[39m\u001B[34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001B[39m\n\u001B[32m    509\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m begin_step, end_step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[32m    510\u001B[39m     callbacks.on_test_batch_begin(begin_step)\n\u001B[32m--> \u001B[39m\u001B[32m511\u001B[39m     logs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    512\u001B[39m     callbacks.on_test_batch_end(end_step, logs)\n\u001B[32m    513\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stop_evaluating:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:241\u001B[39m, in \u001B[36mTensorFlowTrainer._make_function.<locals>.function\u001B[39m\u001B[34m(iterator)\u001B[39m\n\u001B[32m    237\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfunction\u001B[39m(iterator):\n\u001B[32m    238\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[32m    239\u001B[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001B[32m    240\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m241\u001B[39m         opt_outputs = \u001B[43mmulti_step_on_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    242\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_outputs.has_value():\n\u001B[32m    243\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    148\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001B[39m, in \u001B[36mFunction.__call__\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    830\u001B[39m compiler = \u001B[33m\"\u001B[39m\u001B[33mxla\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mnonXla\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m._jit_compile):\n\u001B[32m--> \u001B[39m\u001B[32m833\u001B[39m   result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    835\u001B[39m new_tracing_count = \u001B[38;5;28mself\u001B[39m.experimental_get_tracing_count()\n\u001B[32m    836\u001B[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001B[39m, in \u001B[36mFunction._call\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    875\u001B[39m \u001B[38;5;28mself\u001B[39m._lock.release()\n\u001B[32m    876\u001B[39m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[32m    877\u001B[39m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m878\u001B[39m results = \u001B[43mtracing_compilation\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[32m    880\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    881\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._created_variables:\n\u001B[32m    882\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mCreating variables on a non-first call to a function\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    883\u001B[39m                    \u001B[33m\"\u001B[39m\u001B[33m decorated with tf.function.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[39m, in \u001B[36mcall_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    137\u001B[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001B[32m    138\u001B[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[32m    140\u001B[39m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001B[39m, in \u001B[36mConcreteFunction._call_flat\u001B[39m\u001B[34m(self, tensor_inputs, captured_inputs)\u001B[39m\n\u001B[32m   1318\u001B[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001B[32m   1319\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001B[32m   1320\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[32m   1321\u001B[39m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1322\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_inference_function\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1323\u001B[39m forward_backward = \u001B[38;5;28mself\u001B[39m._select_forward_and_backward_functions(\n\u001B[32m   1324\u001B[39m     args,\n\u001B[32m   1325\u001B[39m     possible_gradient_type,\n\u001B[32m   1326\u001B[39m     executing_eagerly)\n\u001B[32m   1327\u001B[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[39m, in \u001B[36mAtomicFunction.call_preflattened\u001B[39m\u001B[34m(self, args)\u001B[39m\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core.Tensor]) -> Any:\n\u001B[32m    215\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m   flat_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.function_type.pack_output(flat_outputs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[39m, in \u001B[36mAtomicFunction.call_flat\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m record.stop_recording():\n\u001B[32m    250\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._bound_context.executing_eagerly():\n\u001B[32m--> \u001B[39m\u001B[32m251\u001B[39m     outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_bound_context\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[43m.\u001B[49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    256\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    257\u001B[39m     outputs = make_call_op_in_graph(\n\u001B[32m    258\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    259\u001B[39m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[32m    260\u001B[39m         \u001B[38;5;28mself\u001B[39m._bound_context.function_call_options.as_attrs(),\n\u001B[32m    261\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001B[39m, in \u001B[36mContext.call_function\u001B[39m\u001B[34m(self, name, tensor_inputs, num_outputs)\u001B[39m\n\u001B[32m   1686\u001B[39m cancellation_context = cancellation.context()\n\u001B[32m   1687\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1688\u001B[39m   outputs = \u001B[43mexecute\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1689\u001B[39m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1690\u001B[39m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1691\u001B[39m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1692\u001B[39m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1693\u001B[39m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1694\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1695\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1696\u001B[39m   outputs = execute.execute_with_cancellation(\n\u001B[32m   1697\u001B[39m       name.decode(\u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m   1698\u001B[39m       num_outputs=num_outputs,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1702\u001B[39m       cancellation_manager=cancellation_context,\n\u001B[32m   1703\u001B[39m   )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MV_Valeo_Opencampus\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[39m, in \u001B[36mquick_execute\u001B[39m\u001B[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[39m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     52\u001B[39m   ctx.ensure_initialized()\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m   tensors = \u001B[43mpywrap_tfe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m core._NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     56\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 589
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T22:28:52.165316Z",
     "start_time": "2026-01-19T20:05:22.274911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if reducedClassNumber_flag:\n",
    "\n",
    "    #del history_multi_redLabel\n",
    "\n",
    "    match StoppingSelector:\n",
    "        case 'val_loss':\n",
    "            StopCallback_redLabel = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.01,\n",
    "                patience= loss_stop_patience_multi[2],\n",
    "                restore_best_weights=True,\n",
    "                verbose = 2,\n",
    "                start_from_epoch = 1\n",
    "            )\n",
    "        case 'val_f1':\n",
    "            StopCallback_redLabel = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_f1_score',\n",
    "                min_delta=0.005,\n",
    "                patience= loss_stop_patience_multi[2],\n",
    "                restore_best_weights=True,\n",
    "                verbose = 2,\n",
    "                mode='max'\n",
    "            )\n",
    "\n",
    "    #set last 30 layers to be trainable\n",
    "    for layer in base_transfer_model_5.layers[-100:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    inception_multiPhase_redLabel.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), #go to lower learning rate\n",
    "        loss=loss_fun_multi_redLabel,\n",
    "        weighted_metrics=[\"accuracy\",'precision','recall',tf.keras.metrics.F1Score(average='weighted')]\n",
    "    )\n",
    "\n",
    "    history_multi_redLabel = inception_multiPhase_redLabel.fit(\n",
    "        train_generator_redLabel_aug,\n",
    "        validation_data = train_generator_redLabel_val,\n",
    "        epochs=max_epochs,\n",
    "        class_weight = class_weights_redLabel_dict,\n",
    "        callbacks=[StopCallback_redLabel],\n",
    "        verbose = 2 #2 is one line per epoch -\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "166/166 - 381s - 2s/step - accuracy: 0.9263 - f1_score: 0.9264 - loss: 0.2290 - precision: 0.9279 - recall: 0.9259 - val_accuracy: 0.9834 - val_f1_score: 0.9837 - val_loss: 0.0401 - val_precision: 0.9834 - val_recall: 0.9826\n",
      "Epoch 2/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9491 - f1_score: 0.9491 - loss: 0.1529 - precision: 0.9509 - recall: 0.9485 - val_accuracy: 0.9539 - val_f1_score: 0.9564 - val_loss: 0.2458 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 3/100\n",
      "166/166 - 356s - 2s/step - accuracy: 0.9471 - f1_score: 0.9471 - loss: 0.1522 - precision: 0.9553 - recall: 0.9469 - val_accuracy: 0.9705 - val_f1_score: 0.9731 - val_loss: 0.1004 - val_precision: 0.9705 - val_recall: 0.9705\n",
      "Epoch 4/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9601 - f1_score: 0.9600 - loss: 0.1114 - precision: 0.9611 - recall: 0.9593 - val_accuracy: 0.9086 - val_f1_score: 0.9425 - val_loss: 0.1403 - val_precision: 0.9093 - val_recall: 0.9086\n",
      "Epoch 5/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9577 - f1_score: 0.9578 - loss: 0.0812 - precision: 0.9580 - recall: 0.9574 - val_accuracy: 0.8784 - val_f1_score: 0.9229 - val_loss: 0.2053 - val_precision: 0.8791 - val_recall: 0.8784\n",
      "Epoch 6/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9453 - f1_score: 0.9452 - loss: 0.0927 - precision: 0.9455 - recall: 0.9447 - val_accuracy: 0.9728 - val_f1_score: 0.9800 - val_loss: 0.1325 - val_precision: 0.9756 - val_recall: 0.9683\n",
      "Epoch 7/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9715 - f1_score: 0.9715 - loss: 0.0727 - precision: 0.9721 - recall: 0.9712 - val_accuracy: 0.9124 - val_f1_score: 0.9460 - val_loss: 0.1137 - val_precision: 0.9169 - val_recall: 0.9086\n",
      "Epoch 8/100\n",
      "166/166 - 358s - 2s/step - accuracy: 0.9685 - f1_score: 0.9684 - loss: 0.0644 - precision: 0.9689 - recall: 0.9682 - val_accuracy: 0.9856 - val_f1_score: 0.9884 - val_loss: 0.0755 - val_precision: 0.9856 - val_recall: 0.9849\n",
      "Epoch 9/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9716 - f1_score: 0.9716 - loss: 0.0736 - precision: 0.9725 - recall: 0.9715 - val_accuracy: 0.8965 - val_f1_score: 0.9370 - val_loss: 0.1119 - val_precision: 0.8971 - val_recall: 0.8958\n",
      "Epoch 10/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9712 - f1_score: 0.9712 - loss: 0.0649 - precision: 0.9718 - recall: 0.9708 - val_accuracy: 0.9811 - val_f1_score: 0.9839 - val_loss: 0.0785 - val_precision: 0.9811 - val_recall: 0.9811\n",
      "Epoch 11/100\n",
      "166/166 - 355s - 2s/step - accuracy: 0.9734 - f1_score: 0.9734 - loss: 0.0556 - precision: 0.9741 - recall: 0.9732 - val_accuracy: 0.9856 - val_f1_score: 0.9882 - val_loss: 0.1002 - val_precision: 0.9864 - val_recall: 0.9856\n",
      "Epoch 12/100\n",
      "166/166 - 356s - 2s/step - accuracy: 0.9909 - f1_score: 0.9909 - loss: 0.0375 - precision: 0.9909 - recall: 0.9909 - val_accuracy: 0.9902 - val_f1_score: 0.9915 - val_loss: 0.0356 - val_precision: 0.9902 - val_recall: 0.9902\n",
      "Epoch 13/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9679 - f1_score: 0.9679 - loss: 0.0723 - precision: 0.9680 - recall: 0.9679 - val_accuracy: 0.9517 - val_f1_score: 0.9677 - val_loss: 0.1033 - val_precision: 0.9538 - val_recall: 0.9509\n",
      "Epoch 14/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9679 - f1_score: 0.9679 - loss: 0.0719 - precision: 0.9680 - recall: 0.9679 - val_accuracy: 0.9887 - val_f1_score: 0.9898 - val_loss: 0.0459 - val_precision: 0.9887 - val_recall: 0.9887\n",
      "Epoch 15/100\n",
      "166/166 - 358s - 2s/step - accuracy: 0.9818 - f1_score: 0.9818 - loss: 0.0683 - precision: 0.9823 - recall: 0.9817 - val_accuracy: 0.9766 - val_f1_score: 0.9826 - val_loss: 0.0775 - val_precision: 0.9780 - val_recall: 0.9751\n",
      "Epoch 16/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9703 - f1_score: 0.9703 - loss: 0.0608 - precision: 0.9704 - recall: 0.9703 - val_accuracy: 0.9887 - val_f1_score: 0.9902 - val_loss: 0.0416 - val_precision: 0.9887 - val_recall: 0.9872\n",
      "Epoch 17/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9657 - f1_score: 0.9656 - loss: 0.0612 - precision: 0.9658 - recall: 0.9654 - val_accuracy: 0.9864 - val_f1_score: 0.9889 - val_loss: 0.0601 - val_precision: 0.9872 - val_recall: 0.9864\n",
      "Epoch 18/100\n",
      "166/166 - 367s - 2s/step - accuracy: 0.9801 - f1_score: 0.9802 - loss: 0.1020 - precision: 0.9803 - recall: 0.9801 - val_accuracy: 0.5370 - val_f1_score: 0.5823 - val_loss: 3.6066 - val_precision: 0.5370 - val_recall: 0.5370\n",
      "Epoch 19/100\n",
      "166/166 - 365s - 2s/step - accuracy: 0.9680 - f1_score: 0.9681 - loss: 0.1074 - precision: 0.9703 - recall: 0.9669 - val_accuracy: 0.9856 - val_f1_score: 0.9879 - val_loss: 0.0647 - val_precision: 0.9864 - val_recall: 0.9856\n",
      "Epoch 20/100\n",
      "166/166 - 358s - 2s/step - accuracy: 0.9760 - f1_score: 0.9760 - loss: 0.0538 - precision: 0.9770 - recall: 0.9758 - val_accuracy: 0.9804 - val_f1_score: 0.9845 - val_loss: 0.0817 - val_precision: 0.9811 - val_recall: 0.9789\n",
      "Epoch 21/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9871 - f1_score: 0.9871 - loss: 0.0266 - precision: 0.9873 - recall: 0.9869 - val_accuracy: 0.9894 - val_f1_score: 0.9903 - val_loss: 0.0350 - val_precision: 0.9894 - val_recall: 0.9894\n",
      "Epoch 22/100\n",
      "166/166 - 358s - 2s/step - accuracy: 0.9937 - f1_score: 0.9937 - loss: 0.0325 - precision: 0.9937 - recall: 0.9937 - val_accuracy: 0.9849 - val_f1_score: 0.9874 - val_loss: 0.0459 - val_precision: 0.9856 - val_recall: 0.9849\n",
      "Epoch 23/100\n",
      "166/166 - 357s - 2s/step - accuracy: 0.9767 - f1_score: 0.9767 - loss: 0.0711 - precision: 0.9768 - recall: 0.9766 - val_accuracy: 0.9116 - val_f1_score: 0.9463 - val_loss: 0.1228 - val_precision: 0.9123 - val_recall: 0.9116\n",
      "Epoch 24/100\n",
      "166/166 - 356s - 2s/step - accuracy: 0.9735 - f1_score: 0.9735 - loss: 0.0464 - precision: 0.9738 - recall: 0.9732 - val_accuracy: 0.9192 - val_f1_score: 0.9471 - val_loss: 0.1302 - val_precision: 0.9191 - val_recall: 0.9184\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n"
     ]
    }
   ],
   "execution_count": 591
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "[Clearly specify which metrics you'll use to evaluate the model performance, and why you've chosen these metrics.]\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:32:42.430734Z",
     "start_time": "2026-01-19T14:32:42.418731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model 2\n",
    "\n",
    "if model2_flag:\n",
    "\n",
    "    #make one folder for each model to save metrics\n",
    "    model_2_dir = os.path.join(hyperparam_dir,'model_2')\n",
    "    if not os.path.isdir(model_2_dir):\n",
    "        os.makedirs(model_2_dir)\n",
    "\n",
    "    # test accuracy on test data\n",
    "    if balanced_flag:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = model_2_CNN.evaluate(test_generator)\n",
    "\n",
    "        #for classification report\n",
    "        true_labels = test_generator_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = model_2_CNN.predict(test_generator_metrics)\n",
    "\n",
    "    else:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = model_2_CNN.evaluate(test_generator_unbalanced)\n",
    "\n",
    "        true_labels = test_generator_unbalanced_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = model_2_CNN.predict(test_generator_unbalanced_metrics)\n",
    "\n",
    "    #convert to numerical - np.argmax directly does the job\n",
    "    predicted_labels = np.argmax(predicted_labels, axis=-1)\n",
    "\n",
    "    print(f\"Model 2. Test Accuracy: {test_accuracy:.3g} | Test Loss: {test_loss:.3g} | Test Precision: {test_precision:.3g} | Test Recall: {test_recall:.3g} | Test F1 Score: {test_f1_score:.3g}:\")\n",
    "\n",
    "    print(classification_report(true_labels, predicted_labels,target_names = label_list))\n",
    "\n",
    "    #save as dict for future use as well\n",
    "    report = classification_report(true_labels, predicted_labels,target_names = label_list,output_dict=True)\n",
    "    #convert to dataframe for easy use and saving to csv\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    #save to file\n",
    "    metrics_baseline_savename = os.path.join(model_2_dir,'classification_report.csv')\n",
    "\n",
    "    report_df.to_csv(metrics_baseline_savename)\n",
    "\n",
    "    #save model as well for future use\n",
    "    #save the model:\n",
    "    model_2_CNN.save(os.path.join(model_2_dir,'model.keras'))"
   ],
   "outputs": [],
   "execution_count": 503
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:32:42.461751Z",
     "start_time": "2026-01-19T14:32:42.454739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model 3\n",
    "\n",
    "if model3_flag:\n",
    "\n",
    "    #make one folder for each model to save metrics\n",
    "    model_3_dir = os.path.join(hyperparam_dir,'model_3')\n",
    "    if not os.path.isdir(model_3_dir):\n",
    "        os.makedirs(model_3_dir)\n",
    "\n",
    "    # test accuracy on test data\n",
    "    if balanced_flag:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = model_3_CNN.evaluate(test_generator)\n",
    "\n",
    "        #for classification report\n",
    "        true_labels = test_generator_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = model_3_CNN.predict(test_generator_metrics)\n",
    "\n",
    "    else:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = model_3_CNN.evaluate(test_generator_unbalanced)\n",
    "\n",
    "        true_labels = test_generator_unbalanced_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = model_3_CNN.predict(test_generator_unbalanced_metrics)\n",
    "\n",
    "    #convert to numerical - np.argmax directly does the job\n",
    "    predicted_labels = np.argmax(predicted_labels, axis=-1)\n",
    "\n",
    "    print(f\"Model 3. Test Accuracy: {test_accuracy:.3g} | Test Loss: {test_loss:.3g} | Test Precision: {test_precision:.3g} | Test Recall: {test_recall:.3g} | Test F1 Score: {test_f1_score:.3g}:\")\n",
    "\n",
    "    print(classification_report(true_labels, predicted_labels,target_names = label_list))\n",
    "\n",
    "    #save as dict for future use as well\n",
    "    report = classification_report(true_labels, predicted_labels,target_names = label_list,output_dict=True)\n",
    "    #convert to dataframe for easy use and saving to csv\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    #save to file\n",
    "    metrics_baseline_savename = os.path.join(model_3_dir,'classification_report.csv')\n",
    "\n",
    "    report_df.to_csv(metrics_baseline_savename)\n",
    "\n",
    "    #save model as well for future use\n",
    "    #save the model:\n",
    "    model_3_CNN.save(os.path.join(model_3_dir,'model.keras'))"
   ],
   "outputs": [],
   "execution_count": 504
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:32:42.475395Z",
     "start_time": "2026-01-19T14:32:42.468754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model 1\n",
    "\n",
    "if model1_flag:\n",
    "\n",
    "    #make one folder for each model to save metrics\n",
    "    model_1_dir = os.path.join(hyperparam_dir,'model_1')\n",
    "    if not os.path.isdir(model_1_dir):\n",
    "        os.makedirs(model_1_dir)\n",
    "\n",
    "    # test accuracy on test data\n",
    "    if balanced_flag:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = model_1_CNN.evaluate(test_generator)\n",
    "\n",
    "        #for classification report\n",
    "        true_labels = test_generator_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = model_1_CNN.predict(test_generator_metrics)\n",
    "\n",
    "    else:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = model_1_CNN.evaluate(test_generator_unbalanced)\n",
    "\n",
    "        true_labels = test_generator_unbalanced_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = model_1_CNN.predict(test_generator_unbalanced_metrics)\n",
    "\n",
    "    #convert to numerical - np.argmax directly does the job\n",
    "    predicted_labels = np.argmax(predicted_labels, axis=-1)\n",
    "\n",
    "    print(f\"Model 1. Test Accuracy: {test_accuracy:.3g} | Test Loss: {test_loss:.3g} | Test Precision: {test_precision:.3g} | Test Recall: {test_recall:.3g} | Test F1 Score: {test_f1_score:.3g}:\")\n",
    "\n",
    "    print(classification_report(true_labels, predicted_labels,target_names = label_list))\n",
    "\n",
    "    #save as dict for future use as well\n",
    "    report = classification_report(true_labels, predicted_labels,target_names = label_list,output_dict=True)\n",
    "    #convert to dataframe for easy use and saving to csv\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    #save to file\n",
    "    metrics_baseline_savename = os.path.join(model_1_dir,'classification_report.csv')\n",
    "\n",
    "    report_df.to_csv(metrics_baseline_savename)\n",
    "\n",
    "    #save model as well for future use\n",
    "    #save the model:\n",
    "    model_1_CNN.save(os.path.join(model_1_dir,'model.keras'))"
   ],
   "outputs": [],
   "execution_count": 505
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:32:42.488629Z",
     "start_time": "2026-01-19T14:32:42.481398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model transfer feature extraction\n",
    "\n",
    "if feature_extract_flag:\n",
    "\n",
    "    #make one folder for each model to save metrics\n",
    "    model_feat_extract_dir = os.path.join(hyperparam_dir,'InceptionV3_feat_extract')\n",
    "    if not os.path.isdir(model_feat_extract_dir):\n",
    "        os.makedirs(model_feat_extract_dir)\n",
    "\n",
    "    # test accuracy on test data\n",
    "    if balanced_flag:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = inception_feature_extraction_model.evaluate(test_generator_color)\n",
    "\n",
    "        #for classification report\n",
    "        true_labels = test_generator_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = inception_feature_extraction_model.predict(test_generator_metrics_color)\n",
    "\n",
    "    else:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = inception_feature_extraction_model.evaluate(test_generator_unbalanced_color)\n",
    "\n",
    "        true_labels = test_generator_unbalanced_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = inception_feature_extraction_model.predict(test_generator_unbalanced_metrics_color)\n",
    "\n",
    "    #convert to numerical - np.argmax directly does the job\n",
    "    predicted_labels = np.argmax(predicted_labels, axis=-1)\n",
    "\n",
    "    print(f\"Feat. Extract. Model:  Test Accuracy: {test_accuracy:.3g} | Test Loss: {test_loss:.3g} | Test Precision: {test_precision:.3g} | Test Recall: {test_recall:.3g} | Test F1 Score: {test_f1_score:.3g}:\")\n",
    "\n",
    "    print(classification_report(true_labels, predicted_labels,target_names = label_list))\n",
    "\n",
    "    #save as dict for future use as well\n",
    "    report = classification_report(true_labels, predicted_labels,target_names = label_list,output_dict=True)\n",
    "    #convert to dataframe for easy use and saving to csv\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    #save to file\n",
    "    metrics_baseline_savename = os.path.join(model_feat_extract_dir,'classification_report.csv')\n",
    "\n",
    "    report_df.to_csv(metrics_baseline_savename)\n",
    "\n",
    "    #save model as well for future use\n",
    "    #save the model:\n",
    "    inception_feature_extraction_model.save(os.path.join(model_feat_extract_dir,'model.keras'))"
   ],
   "outputs": [],
   "execution_count": 506
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:32:42.501651Z",
     "start_time": "2026-01-19T14:32:42.494633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#for tine tuning model\n",
    "\n",
    "if fine_tune_flag:\n",
    "\n",
    "    #make one folder for each model to save metrics\n",
    "    model_feat_extract_dir = os.path.join(hyperparam_dir,'InceptionV3_fine_tune')\n",
    "    if not os.path.isdir(model_feat_extract_dir):\n",
    "        os.makedirs(model_feat_extract_dir)\n",
    "\n",
    "    # test accuracy on test data\n",
    "    if balanced_flag:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = inception_fine_tune_model.evaluate(test_generator_color)\n",
    "\n",
    "        #for classification report\n",
    "        true_labels = test_generator_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = inception_fine_tune_model.predict(test_generator_metrics_color)\n",
    "\n",
    "    else:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = inception_fine_tune_model.evaluate(test_generator_unbalanced_color)\n",
    "\n",
    "        true_labels = test_generator_unbalanced_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = inception_fine_tune_model.predict(test_generator_unbalanced_metrics_color)\n",
    "\n",
    "    #convert to numerical - np.argmax directly does the job\n",
    "    predicted_labels = np.argmax(predicted_labels, axis=-1)\n",
    "\n",
    "    print(f\"Fine tune Model:  Test Accuracy: {test_accuracy:.3g} | Test Loss: {test_loss:.3g} | Test Precision: {test_precision:.3g} | Test Recall: {test_recall:.3g} | Test F1 Score: {test_f1_score:.3g}:\")\n",
    "\n",
    "    print(classification_report(true_labels, predicted_labels,target_names = label_list))\n",
    "\n",
    "    #save as dict for future use as well\n",
    "    report = classification_report(true_labels, predicted_labels,target_names = label_list,output_dict=True)\n",
    "    #convert to dataframe for easy use and saving to csv\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    #save to file\n",
    "    metrics_baseline_savename = os.path.join(model_feat_extract_dir,'classification_report.csv')\n",
    "\n",
    "    report_df.to_csv(metrics_baseline_savename)\n",
    "\n",
    "    #save model as well for future use\n",
    "    #save the model:\n",
    "    inception_fine_tune_model.save(os.path.join(model_feat_extract_dir,'model.keras'))"
   ],
   "outputs": [],
   "execution_count": 507
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:32:42.514884Z",
     "start_time": "2026-01-19T14:32:42.507654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#for full tine tuning model\n",
    "\n",
    "if full_fine_tune_flag:\n",
    "\n",
    "    #make one folder for each model to save metrics\n",
    "    model_full_fine_tune_dir = os.path.join(hyperparam_dir,'InceptionV3_full_fine_tune')\n",
    "    if not os.path.isdir(model_full_fine_tune_dir):\n",
    "        os.makedirs(model_full_fine_tune_dir)\n",
    "\n",
    "    # test accuracy on test data\n",
    "    if balanced_flag:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = inception_full_fine_tune_model.evaluate(test_generator_color)\n",
    "\n",
    "        #for classification report\n",
    "        true_labels = test_generator_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = inception_full_fine_tune_model.predict(test_generator_metrics_color)\n",
    "\n",
    "    else:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = inception_full_fine_tune_model.evaluate(test_generator_unbalanced_color)\n",
    "\n",
    "        true_labels = test_generator_unbalanced_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = inception_full_fine_tune_model.predict(test_generator_unbalanced_metrics_color)\n",
    "\n",
    "    #convert to numerical - np.argmax directly does the job\n",
    "    predicted_labels = np.argmax(predicted_labels, axis=-1)\n",
    "\n",
    "    print(f\"Full fine tune Model:  Test Accuracy: {test_accuracy:.3g} | Test Loss: {test_loss:.3g} | Test Precision: {test_precision:.3g} | Test Recall: {test_recall:.3g} | Test F1 Score: {test_f1_score:.3g}:\")\n",
    "\n",
    "    print(classification_report(true_labels, predicted_labels,target_names = label_list))\n",
    "\n",
    "    #save as dict for future use as well\n",
    "    report = classification_report(true_labels, predicted_labels,target_names = label_list,output_dict=True)\n",
    "    #convert to dataframe for easy use and saving to csv\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    #save to file\n",
    "    metrics_baseline_savename = os.path.join(model_full_fine_tune_dir,'classification_report.csv')\n",
    "\n",
    "    report_df.to_csv(metrics_baseline_savename)\n",
    "\n",
    "    #save model as well for future use\n",
    "    #save the model:\n",
    "    inception_full_fine_tune_model.save(os.path.join(model_full_fine_tune_dir,'model.keras'))"
   ],
   "outputs": [],
   "execution_count": 508
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T09:33:16.381975Z",
     "start_time": "2026-01-20T09:30:12.769013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#for multi phase full tine tuning model - reduced class number\n",
    "if reducedClassNumber_flag:\n",
    "\n",
    "    #make one folder for each model to save metrics\n",
    "    model_fine_tune_redLabel_dir = os.path.join(hyperparam_dir,'InceptionV3_MultiPhase_reducedLabelNum')\n",
    "    if not os.path.isdir(model_fine_tune_redLabel_dir):\n",
    "        os.makedirs(model_fine_tune_redLabel_dir)\n",
    "\n",
    "    # test accuracy on test data - test accuracy ALWAYS on full test set\n",
    "\n",
    "    test_loss, test_accuracy, test_precision, test_recall,test_f1_score = inception_multiPhase_redLabel.evaluate(test_generator_redLabel)\n",
    "\n",
    "    #for classification report\n",
    "    true_labels = test_generator_redLabel_metrics.classes\n",
    "    # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "    predicted_labels = inception_multiPhase_redLabel.predict(test_generator_redLabel_metrics)\n",
    "\n",
    "    #convert to numerical - np.argmax directly does the job\n",
    "    predicted_labels = np.argmax(predicted_labels, axis=-1)\n",
    "\n",
    "    print(f\"Reduced Label Number:  Test Accuracy: {test_accuracy:.3g} | Test Loss: {test_loss:.3g} | Test Precision: {test_precision:.3g} | Test Recall: {test_recall:.3g} | Test F1 Score: {test_f1_score:.3g}:\")\n",
    "\n",
    "    print(classification_report(true_labels, predicted_labels,target_names = label_list_reduced))\n",
    "\n",
    "    #save as dict for future use as well\n",
    "    report = classification_report(true_labels, predicted_labels,target_names = label_list_reduced,output_dict=True)\n",
    "    #convert to dataframe for easy use and saving to csv\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    #save to file\n",
    "    metrics_baseline_savename = os.path.join(model_fine_tune_redLabel_dir,'classification_report.csv')\n",
    "\n",
    "    report_df.to_csv(metrics_baseline_savename)\n",
    "\n",
    "    #save model as well for future use\n",
    "    #save the model:\n",
    "    inception_multiPhase_redLabel.save(os.path.join(model_fine_tune_redLabel_dir,'model.keras'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 1s/step - accuracy: 0.9873 - f1_score: 0.9882 - loss: 0.0536 - precision: 0.9879 - recall: 0.9873\n",
      "\u001B[1m1656/1656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m117s\u001B[0m 70ms/step\n",
      "Reduced Label Number:  Test Accuracy: 0.987 | Test Loss: 0.0536 | Test Precision: 0.988 | Test Recall: 0.987 | Test F1 Score: 0.988:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      0_Good       0.98      0.99      0.98       238\n",
      " 1_Flat Loop       0.52      0.80      0.63        15\n",
      " 2_Defective       1.00      0.99      0.99      1403\n",
      "\n",
      "    accuracy                           0.99      1656\n",
      "   macro avg       0.83      0.93      0.87      1656\n",
      "weighted avg       0.99      0.99      0.99      1656\n",
      "\n"
     ]
    }
   ],
   "execution_count": 598
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T23:12:58.744232Z",
     "start_time": "2026-01-19T23:12:58.736816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#for multi phase full tine tuning model\n",
    "\n",
    "if multi_phase_fine_tune_flag:\n",
    "\n",
    "    #make one folder for each model to save metrics\n",
    "    model_multi_full_fine_tune_dir = os.path.join(hyperparam_dir,'InceptionV3_MultiPhase_full_fine_tune')\n",
    "    if not os.path.isdir(model_multi_full_fine_tune_dir):\n",
    "        os.makedirs(model_multi_full_fine_tune_dir)\n",
    "\n",
    "    # test accuracy on test data - test accuracy ALWAYS on full test set\n",
    "    if balanced_flag:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = inception_multiPhase_fine_tune_model.evaluate(test_generator_color)\n",
    "\n",
    "        #for classification report\n",
    "        true_labels = test_generator_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = inception_multiPhase_fine_tune_model.predict(test_generator_metrics_color)\n",
    "\n",
    "    else:\n",
    "        test_loss, test_accuracy, test_precision, test_recall,test_f1_score = inception_multiPhase_fine_tune_model.evaluate(test_generator_unbalanced_color)\n",
    "\n",
    "        true_labels = test_generator_unbalanced_metrics.classes\n",
    "        # model.predict directly gives you the output of the last mode layer. so percentages when using i.e. 'softmax'\n",
    "        predicted_labels = inception_multiPhase_fine_tune_model.predict(test_generator_unbalanced_metrics_color)\n",
    "\n",
    "    #convert to numerical - np.argmax directly does the job\n",
    "    predicted_labels = np.argmax(predicted_labels, axis=-1)\n",
    "\n",
    "    print(f\"Full fine tune Model:  Test Accuracy: {test_accuracy:.3g} | Test Loss: {test_loss:.3g} | Test Precision: {test_precision:.3g} | Test Recall: {test_recall:.3g} | Test F1 Score: {test_f1_score:.3g}:\")\n",
    "\n",
    "    print(classification_report(true_labels, predicted_labels,target_names = label_list))\n",
    "\n",
    "    #save as dict for future use as well\n",
    "    report = classification_report(true_labels, predicted_labels,target_names = label_list,output_dict=True)\n",
    "    #convert to dataframe for easy use and saving to csv\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    #save to file\n",
    "    metrics_baseline_savename = os.path.join(model_multi_full_fine_tune_dir,'classification_report.csv')\n",
    "\n",
    "    report_df.to_csv(metrics_baseline_savename)\n",
    "\n",
    "    #save model as well for future use\n",
    "    #save the model:\n",
    "    inception_multiPhase_fine_tune_model.save(os.path.join(model_multi_full_fine_tune_dir,'model.keras'))"
   ],
   "outputs": [],
   "execution_count": 592
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:35:44.286175Z",
     "start_time": "2026-01-19T14:35:44.281394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#clear all models from memory to prevent any bugs and weird behaviour of early stopping\n",
    "\n",
    "#see: https://stackoverflow.com/questions/58137677/keras-model-training-memory-leak\n",
    "\n",
    "del model_1_CNN\n",
    "del model_2_CNN\n",
    "del model_3_CNN\n",
    "\n",
    "del inception_feature_extraction_model\n",
    "del base_transfer_model\n",
    "del inception_fine_tune_model\n",
    "del base_transfer_model_2\n",
    "del inception_full_fine_tune_model\n",
    "del base_transfer_model_3\n",
    "del inception_multiPhase_fine_tune_model\n",
    "del base_transfer_model_4"
   ],
   "outputs": [],
   "execution_count": 510
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:35:50.625410Z",
     "start_time": "2026-01-19T14:35:44.306183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session(\n",
    "    free_memory=True\n",
    ")\n",
    "tf.compat.v1.reset_default_graph()\n"
   ],
   "outputs": [],
   "execution_count": 511
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Comparative Analysis\n",
    "\n",
    "[Compare the performance of your model(s) against the baseline model. Discuss any improvements or setbacks and the reasons behind them.]\n",
    "\n",
    "A table comparing the performances of different models and hyperparameter settings can be found in the github (Model_Performance_overview.xls or Model_Performance_overview.csv).\n",
    "\n",
    "Some results stand out:\n",
    "\n",
    "* data augmentation seems to lower model performance across the board even when we see overfitting in training. The likely reason is that the data itself is very regular without a lot of orientation of the features in the images. Therefore, we well adjust data augmentation in future to exlude image flipping etc.\n",
    "* The transfer learning model performs worse than the 3 relatively simple models. Especially for low image resolutions. The most likely reason is that, as of now we only use feature extraction. For any image size that the model was not originally trained on this will very likely mean a bad performance. For higher resolutions the transfer learning model performs better in comparison\n",
    "* Higher image resolution does not really improve model performance.\n",
    "\n",
    "Some things are still missing in the analysis / evaluation and will be added in the near future:\n",
    "\n",
    "* Transfer learning models with fine tuning\n",
    "* Different transfer learning base architectures\n",
    "* When a best model is found we will tackle the task of identifying the drift label class\n",
    "* More finetuning of hyperparameters for few selected models\n",
    "* class weighting instead of balanced dataset (balanced dataset is very small)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
